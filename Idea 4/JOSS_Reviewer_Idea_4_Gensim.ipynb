{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab6d0d6-578d-466d-a04c-99185f7ed880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb96164-72a7-47d2-b51c-04d0c89e1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "#import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d77d550-c6df-478a-a436-9f7c7ff9a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_OF_INTEREST_FNAME  = glob.glob('/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/*/*/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b16ff6e-32a5-44ca-b766-ef195a0248d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/joss-papers-master/joss.00044/10.21105.joss.00044.pdf\n"
     ]
    }
   ],
   "source": [
    "K = 26\n",
    "print(PAPER_OF_INTEREST_FNAME[K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "652a88a1-6165-4bdc-a101-6172352bea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paper_interest = PAPER_OF_INTEREST_FNAME[K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccdb9a04-ab22-443a-afc9-a5c2065d637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_PDF = [extract_text(Paper_interest)]\n",
    "text = str(POI_PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a87f42ec-5a7f-4016-9b04-974ef54c0ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['DOI: 10.21105/joss.03447\\\\n\\\\nSoftware\\\\n\\\\n• Review\\\\n• Repository\\\\n• Archive\\\\n\\\\nEditor: Jacob Schreiber\\\\n\\\\nReviewers:\\\\n\\\\n• @pps121\\\\n• @amtseng\\\\n\\\\nSubmitted: 16 June 2021\\\\nPublished: 30 September 2021\\\\n\\\\nLicense\\\\nAuthors of papers retain\\\\ncopyright and release the work\\\\nunder a Creative Commons\\\\nAttribution 4.0 International\\\\nLicense (CC BY 4.0).\\\\n\\\\nCOVID-19 Lung Segmentation\\\\n\\\\nRiccardo Biondi∗1, Nico Curti†2, Enrico Giampieri2, and Gastone\\\\nCastellani1\\\\n\\\\n1 Department of Experimental, Diagnostic and Specialty Medicine of Bologna University 2\\\\neDIMESLab, Department of Experimental, Diagnostic and Specialty Medicine of Bologna University\\\\n\\\\nSummary\\\\n\\\\nThe COVID-19 Lung Segmentation project provides a novel, unsupervised and fully auto-\\\\nmated pipeline for the semantic segmentation of ground-glass opacity (GGO) areas in chest\\\\nComputer Tomography (CT) scans of patients affected by COVID-19.\\\\nIn the project we\\\\nprovide a series of scripts and functions for the automated segmentation of lungs 3D areas,\\\\nsegmentation of GGO areas, and estimation of radiomic features.\\\\n\\\\nBoth PowerShell and bash scripts are provided for the scripts management. A possible Snake-\\\\nmake pipeline for the whole segmentation procedure applied to several CT scans (in a multi-\\\\nprocessing environment) is included into the project.\\\\n\\\\nA detailed description of the whole pipeline of processing has been already discussed in Biondi\\\\net al. (2021), where we have showed also the results obtained on public datasets (Jun et\\\\nIn that work we proved the efficiency of the proposed unsupervised method for\\\\nal., 2020).\\\\nthe identification of GGO areas and extraction of informative radiomic features. Radiomic\\\\nfeatures were collected and used to predict clinically relevant scores, with particular focus on\\\\nmortality and the PREDI-CO score (Bartoletti et al., 2020).\\\\n\\\\nStatement of Need\\\\n\\\\nCOronaVirus Disease (COVID-19) has widely spread all over the world since the beginning of\\\\n2020. It is an acute, highly contagious, viral infection mainly involving the respiratory system.\\\\nChest CT scans of patients affected by this condition have shown peculiar patterns of Ground\\\\nGlass Opacities (GGO) and Consolidation (CS) related to the severity and the stage of the\\\\ndisease.\\\\n\\\\nThe correct and fast identification of these patterns is a fundamental task. Up to now,\\\\nthis task has mainly been performed using manual or semi-automatic techniques, which are\\\\ntime-consuming (hours or days), with results dependent on the operator’s expertise.\\\\n\\\\nThis project provides an automated pipeline for the segmentation of GGO areas on chest CT\\\\nscans of patient affected by COVID-19. The segmentation is achieved with a color quantization\\\\nalgorithm, based on k-means clustering, which groups the voxels by color and texture similarity.\\\\nThis approach is preceeded by the lung segmentation, achieved by a public available U-Net\\\\nmodel (Hofmanninger et al., 2020; Johannes Hofmanninger, 2020).\\\\n\\\\nThe pipeline’s performance has been tested on a dataset of 15 labeled chest CT scans. These\\\\nscans were segmented and validated by an expert radiologist. Ten of these scans were extracted\\\\n\\\\n∗co-first author\\\\n†co-first author\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n1\\\\n\\\\n\\\\x0cfrom the public dataset COVID-19 CT Lung and Infection Segmentation Dataset (Jun et al.,\\\\n2020) published on Zenodo. The Department of Diagnostic and Preventive Medicine of the\\\\nIRCCS Policlinic Sant’Orsola-Malpighi provided another 82 scans, with the 5 labeled scans\\\\nused for the evaluation.\\\\n\\\\nWe tested the segmentation performances using the dice coefficient and specificity, sensitivity,\\\\nand precision scores. The average value and the corresponding standard deviation at 1(cid:27) are\\\\nreported in the following table.\\\\n\\\\nDice Score\\\\n0:67 (cid:6) 0:12\\\\n\\\\nSensitivity\\\\n0:66 (cid:6) 0:15\\\\n\\\\nSpecificity\\\\n0:9992 (cid:6) 0:0005\\\\n\\\\nPrecision\\\\n0:75 (cid:6) 0:20\\\\n\\\\nThe proposed unsupervised segmentation pipeline is able to approximate the gold standard\\\\nwith satisfactory results. Given that the amount of information required for the k-means\\\\nmethod training is considerably lower than for CNN methods, while still retaining good results,\\\\nthis segmentation can be implemented with in-patient training (Biondi et al., 2021); as a\\\\nreference, a 3D U-Net-based method (Yan et al., 2020) required two order of magnitude more\\\\ntraining samples to achieve comparable results. With this work we aimed to prove that semi-\\\\nsupervised approaches to segmentation are promising, as they would combine the best effort\\\\nof highly trained physicians to develop true gold standard segmentation and the expertise\\\\nof data analysts to augment those segmentation in full blown models. While the proposed\\\\npipeline is not yet at the accuracy level necessary for assisted diagnostics, we surmise that our\\\\npipeline can be successfully used as a first segmentation method to be used as training for\\\\nother, more specific methods.\\\\n\\\\nAcknowledgments\\\\n\\\\nThe authors acknowledge all the members of the Department of Radiology, IRCCS Azienda\\\\nOspedaliero-Universitaria di Bologna and the SIRM foundation, Italian Society of Medical and\\\\nInterventional Radiology for the support in the development of the project and analysis of the\\\\ndata.\\\\n\\\\nReferences\\\\n\\\\nBartoletti, M., Giannella, M., Scudeller, L., Tedeschi, S., Rinaldi, M., Bussini, L., Fornaro,\\\\nG., Pascale, R., Pancaldi, L., Pasquini, Z., Trapani, F., Badia, L., Campoli, C., Ta-\\\\ndolini, M., Attard, L., Puoti, M., Merli, M., Mussini, C., Menozzi, M., … group, P.\\\\nstudy. (2020). Development and validation of a prediction model for severe respiratory\\\\nfailure in hospitalized patients with SARS-CoV-2 infection: A multicentre cohort study\\\\n(PREDI-CO study). Clinical Microbiology and Infection : The Official Publication of the\\\\nEuropean Society of Clinical Microbiology and Infectious Diseases, 26(11), 1545–1553.\\\\nhttps://doi.org/10.1016/j.cmi.2020.08.003\\\\n\\\\nBiondi, R., Curti, N., Coppola, F., Giampieri, E., Vara, G., Bartoletti, M., Cattabriga, A.,\\\\nCocozza, M. A., Ciccarese, F., De Benedittis, C., Cercenelli, L., Bortolani, B., Marcelli,\\\\nE., Pierotti, L., Strigari, L., Viale, P., Golfieri, R., & Castellani, G. (2021). Classification\\\\nperformance for COVID patient prognosis from automatic AI segmentation—a single-\\\\ncenter study. Applied Sciences, 11(12). https://doi.org/10.3390/app11125438\\\\n\\\\nHofmanninger, J., Prayer, F., Pan, J., Röhrich, S., Prosch, H., & Langs, G. (2020). Auto-\\\\nmatic lung segmentation in routine imaging is primarily a data diversity problem, not a\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n2\\\\n\\\\n\\\\x0cmethodology problem. European Radiology Experimental, 4(1), 50–50. https://doi.org/\\\\n10.1186/s41747-020-00173-2\\\\n\\\\nJohannes Hofmanninger, H. N. (2020). Automated lung segmentation in CT under presence\\\\n\\\\nof severe pathologies. https://github.com/JoHof/lungmask; GitHub.\\\\n\\\\nJun, M., Cheng, G., Yixin, W., Xingle, A., Jiantao, G., Ziqi, Y., Minqing, Z., Xin, L., Xueyuan,\\\\nD., Shucheng, C., Hao, W., Sen, M., Xiaoyu, Y., Ziwei, N., Chen, L., Lu, T., Yuntao,\\\\nZ., Qiongjie, Z., Guoqiang, D., & Jian, H. (2020). COVID-19 CT lung and infection\\\\nsegmentation dataset (Verson 1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.\\\\n3757476\\\\n\\\\nYan, Q., Wang, B., Gong, D., Luo, C., Zhao, W., Shen, J., Shi, Q., Jin, S., Zhang, L., &\\\\nYou, Z. (2020). COVID-19 chest CT image segmentation – a deep convolutional neural\\\\nnetwork solution. http://arxiv.org/abs/2004.10987\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n3\\\\n\\\\n\\\\x0c']\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a121e5-63e8-4535-b922-248f6cf7cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('-\\\\n','')\n",
    "text = text.replace('-\\n','')\n",
    "text = text.replace('\\\\n',' ')\n",
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b41222b9-e1b6-4870-a87e-f567000b4302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['DOI: 10.21105/joss.03447\\\\n\\\\nSoftware\\\\n\\\\n• Review\\\\n• Repository\\\\n• Archive\\\\n\\\\nEditor: Jacob Schreiber\\\\n\\\\nReviewers:\\\\n\\\\n• @pps121\\\\n• @amtseng\\\\n\\\\nSubmitted: 16 June 2021\\\\nPublished: 30 September 2021\\\\n\\\\nLicense\\\\nAuthors of papers retain\\\\ncopyright and release the work\\\\nunder a Creative Commons\\\\nAttribution 4.0 International\\\\nLicense (CC BY 4.0).\\\\n\\\\nCOVID-19 Lung Segmentation\\\\n\\\\nRiccardo Biondi∗1, Nico Curti†2, Enrico Giampieri2, and Gastone\\\\nCastellani1\\\\n\\\\n1 Department of Experimental, Diagnostic and Specialty Medicine of Bologna University 2\\\\neDIMESLab, Department of Experimental, Diagnostic and Specialty Medicine of Bologna University\\\\n\\\\nSummary\\\\n\\\\nThe COVID-19 Lung Segmentation project provides a novel, unsupervised and fully auto-\\\\nmated pipeline for the semantic segmentation of ground-glass opacity (GGO) areas in chest\\\\nComputer Tomography (CT) scans of patients affected by COVID-19.\\\\nIn the project we\\\\nprovide a series of scripts and functions for the automated segmentation of lungs 3D areas,\\\\nsegmentation of GGO areas, and estimation of radiomic features.\\\\n\\\\nBoth PowerShell and bash scripts are provided for the scripts management. A possible Snake-\\\\nmake pipeline for the whole segmentation procedure applied to several CT scans (in a multi-\\\\nprocessing environment) is included into the project.\\\\n\\\\nA detailed description of the whole pipeline of processing has been already discussed in Biondi\\\\net al. (2021), where we have showed also the results obtained on public datasets (Jun et\\\\nIn that work we proved the efficiency of the proposed unsupervised method for\\\\nal., 2020).\\\\nthe identification of GGO areas and extraction of informative radiomic features. Radiomic\\\\nfeatures were collected and used to predict clinically relevant scores, with particular focus on\\\\nmortality and the PREDI-CO score (Bartoletti et al., 2020).\\\\n\\\\nStatement of Need\\\\n\\\\nCOronaVirus Disease (COVID-19) has widely spread all over the world since the beginning of\\\\n2020. It is an acute, highly contagious, viral infection mainly involving the respiratory system.\\\\nChest CT scans of patients affected by this condition have shown peculiar patterns of Ground\\\\nGlass Opacities (GGO) and Consolidation (CS) related to the severity and the stage of the\\\\ndisease.\\\\n\\\\nThe correct and fast identification of these patterns is a fundamental task. Up to now,\\\\nthis task has mainly been performed using manual or semi-automatic techniques, which are\\\\ntime-consuming (hours or days), with results dependent on the operator’s expertise.\\\\n\\\\nThis project provides an automated pipeline for the segmentation of GGO areas on chest CT\\\\nscans of patient affected by COVID-19. The segmentation is achieved with a color quantization\\\\nalgorithm, based on k-means clustering, which groups the voxels by color and texture similarity.\\\\nThis approach is preceeded by the lung segmentation, achieved by a public available U-Net\\\\nmodel (Hofmanninger et al., 2020; Johannes Hofmanninger, 2020).\\\\n\\\\nThe pipeline’s performance has been tested on a dataset of 15 labeled chest CT scans. These\\\\nscans were segmented and validated by an expert radiologist. Ten of these scans were extracted\\\\n\\\\n∗co-first author\\\\n†co-first author\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n1\\\\n\\\\n\\\\x0cfrom the public dataset COVID-19 CT Lung and Infection Segmentation Dataset (Jun et al.,\\\\n2020) published on Zenodo. The Department of Diagnostic and Preventive Medicine of the\\\\nIRCCS Policlinic Sant’Orsola-Malpighi provided another 82 scans, with the 5 labeled scans\\\\nused for the evaluation.\\\\n\\\\nWe tested the segmentation performances using the dice coefficient and specificity, sensitivity,\\\\nand precision scores. The average value and the corresponding standard deviation at 1(cid:27) are\\\\nreported in the following table.\\\\n\\\\nDice Score\\\\n0:67 (cid:6) 0:12\\\\n\\\\nSensitivity\\\\n0:66 (cid:6) 0:15\\\\n\\\\nSpecificity\\\\n0:9992 (cid:6) 0:0005\\\\n\\\\nPrecision\\\\n0:75 (cid:6) 0:20\\\\n\\\\nThe proposed unsupervised segmentation pipeline is able to approximate the gold standard\\\\nwith satisfactory results. Given that the amount of information required for the k-means\\\\nmethod training is considerably lower than for CNN methods, while still retaining good results,\\\\nthis segmentation can be implemented with in-patient training (Biondi et al., 2021); as a\\\\nreference, a 3D U-Net-based method (Yan et al., 2020) required two order of magnitude more\\\\ntraining samples to achieve comparable results. With this work we aimed to prove that semi-\\\\nsupervised approaches to segmentation are promising, as they would combine the best effort\\\\nof highly trained physicians to develop true gold standard segmentation and the expertise\\\\nof data analysts to augment those segmentation in full blown models. While the proposed\\\\npipeline is not yet at the accuracy level necessary for assisted diagnostics, we surmise that our\\\\npipeline can be successfully used as a first segmentation method to be used as training for\\\\nother, more specific methods.\\\\n\\\\nAcknowledgments\\\\n\\\\nThe authors acknowledge all the members of the Department of Radiology, IRCCS Azienda\\\\nOspedaliero-Universitaria di Bologna and the SIRM foundation, Italian Society of Medical and\\\\nInterventional Radiology for the support in the development of the project and analysis of the\\\\ndata.\\\\n\\\\nReferences\\\\n\\\\nBartoletti, M., Giannella, M., Scudeller, L., Tedeschi, S., Rinaldi, M., Bussini, L., Fornaro,\\\\nG., Pascale, R., Pancaldi, L., Pasquini, Z., Trapani, F., Badia, L., Campoli, C., Ta-\\\\ndolini, M., Attard, L., Puoti, M., Merli, M., Mussini, C., Menozzi, M., … group, P.\\\\nstudy. (2020). Development and validation of a prediction model for severe respiratory\\\\nfailure in hospitalized patients with SARS-CoV-2 infection: A multicentre cohort study\\\\n(PREDI-CO study). Clinical Microbiology and Infection : The Official Publication of the\\\\nEuropean Society of Clinical Microbiology and Infectious Diseases, 26(11), 1545–1553.\\\\nhttps://doi.org/10.1016/j.cmi.2020.08.003\\\\n\\\\nBiondi, R., Curti, N., Coppola, F., Giampieri, E., Vara, G., Bartoletti, M., Cattabriga, A.,\\\\nCocozza, M. A., Ciccarese, F., De Benedittis, C., Cercenelli, L., Bortolani, B., Marcelli,\\\\nE., Pierotti, L., Strigari, L., Viale, P., Golfieri, R., & Castellani, G. (2021). Classification\\\\nperformance for COVID patient prognosis from automatic AI segmentation—a single-\\\\ncenter study. Applied Sciences, 11(12). https://doi.org/10.3390/app11125438\\\\n\\\\nHofmanninger, J., Prayer, F., Pan, J., Röhrich, S., Prosch, H., & Langs, G. (2020). Auto-\\\\nmatic lung segmentation in routine imaging is primarily a data diversity problem, not a\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n2\\\\n\\\\n\\\\x0cmethodology problem. European Radiology Experimental, 4(1), 50–50. https://doi.org/\\\\n10.1186/s41747-020-00173-2\\\\n\\\\nJohannes Hofmanninger, H. N. (2020). Automated lung segmentation in CT under presence\\\\n\\\\nof severe pathologies. https://github.com/JoHof/lungmask; GitHub.\\\\n\\\\nJun, M., Cheng, G., Yixin, W., Xingle, A., Jiantao, G., Ziqi, Y., Minqing, Z., Xin, L., Xueyuan,\\\\nD., Shucheng, C., Hao, W., Sen, M., Xiaoyu, Y., Ziwei, N., Chen, L., Lu, T., Yuntao,\\\\nZ., Qiongjie, Z., Guoqiang, D., & Jian, H. (2020). COVID-19 CT lung and infection\\\\nsegmentation dataset (Verson 1.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.\\\\n3757476\\\\n\\\\nYan, Q., Wang, B., Gong, D., Luo, C., Zhao, W., Shen, J., Shi, Q., Jin, S., Zhang, L., &\\\\nYou, Z. (2020). COVID-19 chest CT image segmentation – a deep convolutional neural\\\\nnetwork solution. http://arxiv.org/abs/2004.10987\\\\n\\\\nBiondi et al., (2021). COVID-19 Lung Segmentation. Journal of Open Source Software, 6(65), 3447. https://doi.org/10.21105/joss.03447\\\\n\\\\n3\\\\n\\\\n\\\\x0c']\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c8325b-4c98-40af-aefb-ebbb77ce72b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Volumes/Seagate Backup Plus Drive/JOSS Project/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1d743e1-7362-4598-b8e1-4f3ce64477ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download('punkt') #tokenizer, run once\n",
    "download('stopwords') #stopwords dictionary, run once\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e54dd617-5377-4912-ac66-8bf40a5fc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = (POI_PDF)\n",
    "\n",
    "corpus = [preprocess(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9359032d-9993-4117-978a-bd44f0de01a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doi'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "579e750c-570d-47cd-ba28-bf18b212466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_docs(corpus, texts,  condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus, texts and labels given the function condition_on_doc which takes\n",
    "    a doc.\n",
    "    The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    #labels = [i for (i, doc) in zip(labels, corpus) if condition_on_doc(doc)]\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "711f0cae-6493-492f-8951-d220174c0af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "corpus, texts = filter_docs(corpus, texts,  lambda doc: (len(doc) != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcf77b22-8f4b-437d-ae74-480f60122b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c90404f-35f4-4d51-9d76-1ec7d8c82fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbad1356-b19a-4d19-b890-c0237a535196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "corpus, texts = filter_docs(corpus, texts,  lambda doc: has_vector_representation(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "caef99bf-be23-4320-9804-fa8b58404b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =[]\n",
    "for doc in corpus[0]: #look up each doc in model\n",
    "    x.append(document_vector(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53df68e9-cbdd-4e61-8835-facf832f48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x) #list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1425b785-e7d4-44da-aece-6a38e48a0a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90f37441-4695-445f-8a8a-30632e5989b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['able', 'accuracy', 'achieve', 'achieved', 'acknowledge',\n",
       "       'acknowledgments', 'acute', 'affected', 'ai', 'aimed', 'al',\n",
       "       'algorithm', 'already', 'also', 'amount', 'amtseng', 'analysis',\n",
       "       'analysts', 'another', 'applied', 'approach', 'approaches',\n",
       "       'approximate', 'archive', 'areas', 'assisted', 'attard',\n",
       "       'attribution', 'augment', 'author', 'authors', 'automated',\n",
       "       'automatic', 'available', 'average', 'azienda', 'badia',\n",
       "       'bartoletti', 'based', 'bash', 'beginning', 'benedittis', 'best',\n",
       "       'biondi', 'blown', 'bologna', 'bortolani', 'bussini', 'campoli',\n",
       "       'castellani', 'cattabriga', 'cc', 'center', 'cercenelli', 'chen',\n",
       "       'cheng', 'chest', 'ciccarese', 'classification', 'clinical',\n",
       "       'clinically', 'clustering', 'cnn', 'cocozza', 'coefficient',\n",
       "       'cohort', 'collected', 'color', 'combine', 'commons', 'comparable',\n",
       "       'computer', 'condition', 'considerably', 'consolidation',\n",
       "       'contagious', 'convolutional', 'coppola', 'copyright',\n",
       "       'coronavirus', 'correct', 'corresponding', 'covid', 'creative',\n",
       "       'cs', 'ct', 'curti', 'data', 'dataset', 'datasets', 'days', 'de',\n",
       "       'deep', 'department', 'dependent', 'description', 'detailed',\n",
       "       'develop', 'development', 'deviation', 'di', 'diagnostic',\n",
       "       'diagnostics', 'dice', 'discussed', 'disease', 'diseases',\n",
       "       'diversity', 'doi', 'dolini', 'edimeslab', 'editor', 'efficiency',\n",
       "       'effort', 'enrico', 'environment', 'estimation', 'et', 'european',\n",
       "       'evaluation', 'experimental', 'expert', 'expertise', 'extracted',\n",
       "       'extraction', 'failure', 'fast', 'features', 'first', 'focus',\n",
       "       'following', 'fornaro', 'foundation', 'full', 'fully', 'functions',\n",
       "       'fundamental', 'gastone', 'ggo', 'giampieri', 'giannella',\n",
       "       'github', 'given', 'glass', 'gold', 'golfieri', 'gong', 'good',\n",
       "       'ground', 'group', 'groups', 'guoqiang', 'hao', 'highly',\n",
       "       'hofmanninger', 'hospitalized', 'hours', 'http', 'https',\n",
       "       'identification', 'image', 'imaging', 'implemented', 'included',\n",
       "       'infection', 'infectious', 'information', 'informative',\n",
       "       'international', 'interventional', 'involving', 'irccs', 'italian',\n",
       "       'jacob', 'jian', 'jiantao', 'jin', 'johannes', 'journal', 'jun',\n",
       "       'june', 'labeled', 'langs', 'level', 'license', 'lower', 'lu',\n",
       "       'lung', 'lungs', 'luo', 'magnitude', 'mainly', 'make',\n",
       "       'management', 'manual', 'marcelli', 'mated', 'matic', 'medical',\n",
       "       'medicine', 'members', 'menozzi', 'merli', 'method', 'methodology',\n",
       "       'methods', 'microbiology', 'minqing', 'model', 'models',\n",
       "       'mortality', 'multicentre', 'mussini', 'necessary', 'need',\n",
       "       'network', 'neural', 'nico', 'novel', 'obtained', 'official',\n",
       "       'opacities', 'opacity', 'open', 'operator', 'order', 'pan',\n",
       "       'pancaldi', 'papers', 'particular', 'pascale', 'pasquini',\n",
       "       'pathologies', 'patient', 'patients', 'patterns', 'peculiar',\n",
       "       'performance', 'performances', 'performed', 'physicians',\n",
       "       'pierotti', 'pipeline', 'policlinic', 'possible', 'powershell',\n",
       "       'prayer', 'preceeded', 'precision', 'predict', 'prediction',\n",
       "       'presence', 'preventive', 'primarily', 'problem', 'procedure',\n",
       "       'processing', 'prognosis', 'project', 'promising', 'proposed',\n",
       "       'prosch', 'prove', 'proved', 'provide', 'provided', 'provides',\n",
       "       'public', 'publication', 'published', 'puoti', 'qiongjie',\n",
       "       'quantization', 'radiologist', 'radiology', 'radiomic',\n",
       "       'reference', 'references', 'related', 'release', 'relevant',\n",
       "       'reported', 'repository', 'required', 'respiratory', 'results',\n",
       "       'retain', 'retaining', 'review', 'reviewers', 'riccardo',\n",
       "       'rinaldi', 'routine', 'röhrich', 'samples', 'sant', 'satisfactory',\n",
       "       'scans', 'schreiber', 'sciences', 'score', 'scores', 'scripts',\n",
       "       'scudeller', 'segmentation', 'segmented', 'semantic', 'sen',\n",
       "       'sensitivity', 'september', 'series', 'set', 'several', 'severe',\n",
       "       'severity', 'shen', 'shi', 'showed', 'shown', 'shucheng',\n",
       "       'similarity', 'since', 'sirm', 'society', 'software', 'solution',\n",
       "       'source', 'specialty', 'specific', 'specificity', 'spread',\n",
       "       'stage', 'standard', 'statement', 'still', 'strigari', 'study',\n",
       "       'submitted', 'successfully', 'summary', 'supervised', 'support',\n",
       "       'surmise', 'system', 'table', 'task', 'techniques', 'tedeschi',\n",
       "       'ten', 'tested', 'texture', 'tomography', 'trained', 'training',\n",
       "       'trapani', 'true', 'two', 'university', 'unsupervised', 'used',\n",
       "       'using', 'validated', 'validation', 'value', 'vara', 'verson',\n",
       "       'viale', 'viral', 'voxels', 'wang', 'whole', 'widely', 'work',\n",
       "       'world', 'would', 'xiaoyu', 'xin', 'xingle', 'xueyuan', 'yan',\n",
       "       'yet', 'yixin', 'yuntao', 'z', 'zenodo', 'zhang', 'zhao', 'ziqi',\n",
       "       'ziwei'], dtype='<U15')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(corpus[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "958f8deb-7c57-40b8-af2a-0e3f02ff685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 =[]\n",
    "for doc in np.unique(np.array(corpus[0])): #look up each doc in model\n",
    "    x2.append(document_vector(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "687c849c-d455-455d-b261-74f959b159b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(x2) #list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14978b5e-12ab-4972-868b-8945af45d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word2vec_vector2 = X2.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e7001d3-8aff-49a2-9f03-153e4878fb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 0.7675735950469971),\n",
       " ('o', 0.7509527802467346),\n",
       " ('f', 0.7381659150123596),\n",
       " ('b', 0.7305057644844055),\n",
       " ('r', 0.7286273837089539),\n",
       " ('¬', 0.7181587815284729),\n",
       " ('ts', 0.7167741060256958),\n",
       " ('d', 0.7157739400863647),\n",
       " ('ar', 0.7124439477920532),\n",
       " ('i', 0.7066262364387512)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(average_word2vec_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b184c73-28bf-4c94-ac27-e4e446649fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 300)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78779473-6ff6-4be9-a20f-807b6028f395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 300)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e0c6b0e-a149-41ac-8d43-7c38954f2c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f20eab88-049e-4616-a4f1-643771224f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word2vec_vector = X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7e6c8c44-c2ea-4fb7-b62a-6af1a6135947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 0.7642236948013306),\n",
       " ('o', 0.7457115054130554),\n",
       " ('f', 0.7363426685333252),\n",
       " ('b', 0.726196825504303),\n",
       " ('ts', 0.7221477627754211),\n",
       " ('r', 0.7220396399497986),\n",
       " ('¬', 0.7184414863586426),\n",
       " ('d', 0.7125791311264038),\n",
       " ('t', 0.7109199166297913),\n",
       " ('ar', 0.7107546329498291)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(average_word2vec_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5022c29d-57e7-49bf-92e8-3d5a275bca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 0.778066098690033),\n",
       " ('o', 0.7700537443161011),\n",
       " ('t', 0.7625486254692078),\n",
       " ('r', 0.7494496703147888),\n",
       " ('ts', 0.7428569197654724),\n",
       " ('u', 0.7180385589599609),\n",
       " ('¬', 0.7121788859367371),\n",
       " ('f', 0.7076941728591919),\n",
       " ('cks', 0.7059786319732666),\n",
       " ('ta', 0.698557436466217)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(X[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614dbb07-4815-4c2f-a54c-9a7ae205a5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('theJournal', 0.6163490414619446),\n",
       " ('theAmerican_Journal', 0.5941680669784546),\n",
       " ('Annals', 0.5925253629684448),\n",
       " ('Jounal', 0.5823094248771667),\n",
       " ('journal', 0.5741861462593079),\n",
       " ('journal_Annals', 0.5684102773666382),\n",
       " ('PATRICK_JACKSON', 0.5683403015136719),\n",
       " ('Physiology_Gastrointestinal', 0.5631081461906433),\n",
       " ('By_LULADEY_B.', 0.5580130219459534),\n",
       " ('Roentgenology_AJR', 0.557891845703125),\n",
       " ('Gazette', 0.5572773814201355),\n",
       " ('TADESSE', 0.5548046231269836),\n",
       " ('•_GANNETT_STAFF_WRITER', 0.5463052988052368),\n",
       " ('currier@sturgisjournal.com', 0.545045793056488),\n",
       " ('Herald', 0.5421846508979797),\n",
       " ('journal_Archives', 0.5398844480514526),\n",
       " ('journal_Cell_Metabolism', 0.5383172035217285),\n",
       " ('Bulletin', 0.5375578999519348),\n",
       " ('ESTEBAN_PARRA', 0.5362104177474976),\n",
       " ('Clinical_Nutrition_Vol', 0.5346276164054871)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('Journal', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cde4d0-3175-4631-8345-a07fc3446de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
