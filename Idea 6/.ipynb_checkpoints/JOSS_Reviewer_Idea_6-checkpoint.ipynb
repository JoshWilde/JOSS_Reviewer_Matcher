{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61f044f-c55b-46ee-aeff-7f8a095823f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "747540be-db11-4a7d-bfef-076ab10be339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JOSS_PDF_Cleaner import Clean_PDF\n",
    "import re\n",
    "from termcolor import colored\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0000cd2a-409c-4345-bf40-f9a6a7549c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "#import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6558d3b4-12b0-4b71-951a-410f2d32f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Volumes/Seagate Backup Plus Drive/JOSS Project/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62beab1d-987d-4152-a2b9-6f07b1b92aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "download('punkt') #tokenizer, run once\n",
    "download('stopwords') #stopwords dictionary, run once\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6477fa-0ce7-4fe3-bd57-499143a4c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_OF_INTEREST_FNAME  = glob.glob('/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/*/*/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561a1440-04ea-4d29-8193-4c535262713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/joss-papers-master/joss.00592/10.21105.joss.00592.pdf\n"
     ]
    }
   ],
   "source": [
    "K = 260\n",
    "print(PAPER_OF_INTEREST_FNAME[K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21ee987-63c5-4f14-91fc-1423898371e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paper_interest = '/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/joss-papers-master/joss.03447/10.21105.joss.03447.pdf' #PAPER_OF_INTEREST_FNAME[K]\n",
    "Paper_interest = PAPER_OF_INTEREST_FNAME[K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245bd4bc-671b-4f18-8f64-a2994ccb0037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msummary\n",
      "\u001b[0m\n",
      "\u001b[31mdoi: 10.21105/joss.00592\n",
      "\u001b[0m\n",
      "\u001b[31msoftware\n",
      "\u001b[0m\n",
      "\u001b[31m• review\n",
      "• repository\n",
      "• archive\n",
      "\u001b[0m\n",
      "\u001b[31msubmitted: 12 december 2017\n",
      "published: 15 june 2018\n",
      "\u001b[0m\n",
      "\u001b[31mlicense\n",
      "authors of papers retain copyright\n",
      "and release the work under a cre-\n",
      "ative commons attribution 4.0 in-\n",
      "ternational license (cc-by).\n",
      "\u001b[0m\n",
      "\u001b[32maronnax: an idealised isopycnal ocean model\n",
      "\u001b[0m\n",
      "\u001b[31medward w. doddridge1 and alexey radul2\n",
      "\u001b[0m\n",
      "\u001b[31m1 earth, atmospheric and planetary science, massachusetts institute of technology, cambridge,\n",
      "ma, usa 2 brain and cognitive science, massachusetts institute of technology, cambridge, ma,\n",
      "usa\n",
      "\u001b[0m\n",
      "\u001b[32maronnax is a highly idealised model for simulating large-scale (100-1000km) flows in the\n",
      "ocean. aronnax is intended for theoretical and empirical oceanographers, as a (relatively)\n",
      "fast and easy-to-use simulation model, bridging the gap between pencil-and-paper on one\n",
      "hand, and more faithful (and complex) computational models on the other. the numerical\n",
      "core is written in fortran to improve performance, and wrapped in python to improve\n",
      "usability.\n",
      "\u001b[0m\n",
      "\u001b[32maronnax is an isopyncal model: it approximates the ocean as a number of discrete homo-\n",
      "geneous layers with spatially variable thicknesses. these layers are stacked vertically and\n",
      "the density difference between neighbouring layers is specified by the user. other widely\n",
      "used vertical coordinates require solving the equations of motion at specified vertical lev-\n",
      "els where the density is allowed to vary (s. m. griffies et al. 2000). representing the\n",
      "large-scale ocean circulation in layers contributes to aronnax’s speed: one needs only a\n",
      "few layers to achieve the same fidelity as 50 or more fixed vertical levels (stewart et al.\n",
      "2017).\n",
      "\u001b[0m\n",
      "\u001b[32maronnax serves three distinct purposes. firstly, many of the studies that use a model\n",
      "like aronnax do not provide the source code, see e.g. (davis, lique, and johnson 2014,\n",
      "février, sirven, and herbaut (2007), johnson and marshall (2002), stern (1998)). this\n",
      "increases the likelihood that coding errors go undetected, and requires that each research\n",
      "group spend time developing their own idealised model. aronnax solves these problems\n",
      "by providing an open source, tested model for the community to use. secondly, aronnax\n",
      "furthers the goals of scientific reproducibility since a simulation can be entirely specified\n",
      "with a set of input files and a version number. thirdly, aronnax provides an easy-to-use\n",
      "model that may be included in future modelling hierarchies with minimal effort, thereby\n",
      "enabling new research questions to be addressed.\n",
      "\u001b[0m\n",
      "\u001b[32mthere are a number of other publicly available ocean models. of these the most abundant\n",
      "are general circulation models and quasigeostrophic models. general circulation models\n",
      "such as nemo, gold, mom6, and mitgcm solve a less idealised version of the navier-\n",
      "stokes equations and can be coupled with sea ice and atmospheric models to create\n",
      "fully coupled climate models. because the underlying equations are derived with fewer\n",
      "approximations these models can more faithfully simulate a wider range of flow regimes.\n",
      "however, this comes at a price; general circulation models are extremely complex, with\n",
      "numerous free parameters that must be specified, often prior to compiling the source code.\n",
      "it is possible to use most of these models in idealised configurations, but doing so requires\n",
      "a substantial investment of time from the user, and non-trivial computing resources. in\n",
      "comparison, aronnax is easy to install and cheap to run.\n",
      "\u001b[0m\n",
      "\u001b[32mthe other abundant class of models is quasigeostrophic models. geostrophy is a balance\n",
      "between the coriolis force and the horizontal gradient of the pressure field; flows in\n",
      "which the coriolis force and the horizontal pressure gradient almost balance are known\n",
      "\u001b[0m\n",
      "\u001b[31mdoddridge et al., (2018). aronnax: an idealised isopycnal ocean model. journal of open source software, 3(26), 592.\n",
      "https://doi.org/10.21105/joss.00592\n",
      "\u001b[0m\n",
      "\u001b[31m1\n",
      "\u001b[0m\n",
      "\u001b[32mas quasigeostrophic. quasigeostrophic models of the ocean make use of this near balance\n",
      "and a number of other assumptions to simplify the equations of motion from a system of\n",
      "five coupled partial differential equations to a single partial differential equation (vallis\n",
      "2006). quasigeostrophic models range in complexity from qgcm, which includes the\n",
      "option of a coupled atmosphere, to doubly periodic quasigeostrophic turbulence models\n",
      "such as pyqg and qgmodel. while quasigeostrophic models are extremely useful, there\n",
      "are some problems for which they are ill-suited. for example, the adjustment of the ocean\n",
      "circulation often occurs through ageostrophic motions such as boundary waves (johnson\n",
      "and marshall 2002), which are not represented in quasigeostrophic models. in addition,\n",
      "quasigeostrophic models are limited in their representation of sloping bathymetry (depth\n",
      "of the sea floor). for these reasons it may be preferable to use an idealised non-linear\n",
      "model such as aronnax.\n",
      "\u001b[0m\n",
      "\u001b[32maronnax is mit licensed and can be retrieved from github at https://github.com/\n",
      "edoddridge/aronnax.\n",
      "\u001b[0m\n",
      "\u001b[31mreferences\n",
      "\u001b[0m\n",
      "\u001b[31mdavis, peter e d, camille lique, and helen l. johnson. 2014. “on the link between arctic\n",
      "sea ice decline and the freshwater content of the beaufort gyre: insights from a simple\n",
      "process model.” j. clim. 27 (21):8170–84. https://doi.org/10.1175/jcli-d-14-00090.1.\n",
      "\u001b[0m\n",
      "\u001b[31mfévrier, sabine, jérôme sirven, and christophe herbaut. 2007. “interaction of a coastal\n",
      "j. phys.\n",
      "kelvin wave with the mean state in the gulf stream separation area.”\n",
      "oceanogr. 37 (6):1429–44. https://doi.org/10.1175/jpo3062.1.\n",
      "\u001b[0m\n",
      "\u001b[31mgriffies, stephen m, claus böning, frank o. bryan, eric p. chassignet, rudiger gerdes,\n",
      "hiroyasu hasumi, anthony hirst, anne-marie treguier, and david webb. 2000. “de-\n",
      "velopments in ocean climate modelling.” ocean model. 2 (2000):123–92. http://www.\n",
      "sciencedirect.com/science/article/pii/s1463500300000147.\n",
      "\u001b[0m\n",
      "\u001b[31mjohnson, helen l., and david p. marshall.\n",
      "atlantic response to thermohaline variability.”\n",
      "http://dx.doi.org/10.1175/1520-0485(2002)032{\\%}3c1121:atftsa{\\%}3e2.0.co;2.\n",
      "\u001b[0m\n",
      "\u001b[32m“a theory for the surface\n",
      "oceanogr., 1121–32.\n",
      "\u001b[0m\n",
      "\u001b[32mj. phys.\n",
      "\u001b[0m\n",
      "\u001b[31m2002.\n",
      "\u001b[0m\n",
      "\u001b[31mstern, melvin e. 1998. “separation of a density current from the bottom of a con-\n",
      "tinental slope.” j. phys. oceanogr. 28 (10):2040–9. https://doi.org/10.1175/1520-\n",
      "0485(1998)028<2040:soadcf>2.0.co;2.\n",
      "\u001b[0m\n",
      "\u001b[31mstewart, k.d., a.mcc. hogg, s.m. griffies, a.p. heerdegen, m.l. ward, p. spence, and\n",
      "m.h. england. 2017. “vertical resolution of baroclinic modes in global ocean models.”\n",
      "ocean model. 113 (may). elsevier ltd:50–65. https://doi.org/10.1016/j.ocemod.2017.03.\n",
      "012.\n",
      "\u001b[0m\n",
      "\u001b[31mvallis, geoffrey k. 2006. atmospheric and oceanic fluid dynamics. cambridge, uk:\n",
      "cambridge university press.\n",
      "\u001b[0m\n",
      "\u001b[31mdoddridge et al., (2018). aronnax: an idealised isopycnal ocean model. journal of open source software, 3(26), 592.\n",
      "https://doi.org/10.21105/joss.00592\n",
      "\u001b[0m\n",
      "\u001b[31m2\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "texts = ''\n",
    "arr = []\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "for page_layout in extract_pages(Paper_interest):\n",
    "    for element in page_layout:\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            score = Clean_PDF(element.get_text().lower())\n",
    "            #print(score)\n",
    "            if score == 0:\n",
    "                print(colored(element.get_text().lower(), 'green'))\n",
    "                arr.append(element.get_text())\n",
    "                texts = texts  + element.get_text() + ' '\n",
    "            else:\n",
    "                print(colored(element.get_text().lower(), 'red'))\n",
    "            #arr.append(element.get_text())\n",
    "            #texts = texts  + element.get_text() + ' '\n",
    "arr = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9090cda9-50ed-400f-9b84-f84b33ceca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aronnax: An idealised isopycnal ocean model\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8033d83-6936-44e9-bfa5-37853a250cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f718e2-b46f-4d03-908b-8e5f2b01fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/wyv1g7hn08z6pv25vg868lww0000gn/T/ipykernel_15550/3494385313.py:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  sum_vector_text = sum_vector_text + model.wv[corpus[0][i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aronnax\n",
      "idealised\n",
      "isopycnal\n",
      "aronnax\n",
      "idealised\n",
      "aronnax\n",
      "fortran\n",
      "aronnax\n",
      "isopyncal\n",
      "neighbouring\n",
      "griffies\n",
      "aronnax\n",
      "aronnax\n",
      "aronnax\n",
      "lique\n",
      "sirven\n",
      "herbaut\n",
      "idealised\n",
      "aronnax\n",
      "aronnax\n",
      "aronnax\n",
      "modelling\n",
      "quasigeostrophic\n",
      "mitgcm\n",
      "idealised\n",
      "navierstokes\n",
      "idealised\n",
      "aronnax\n",
      "quasigeostrophic\n",
      "geostrophy\n",
      "quasigeostrophic\n",
      "quasigeostrophic\n",
      "vallis\n",
      "quasigeostrophic\n",
      "qgcm\n",
      "quasigeostrophic\n",
      "pyqg\n",
      "qgmodel\n",
      "quasigeostrophic\n",
      "ageostrophic\n",
      "quasigeostrophic\n",
      "quasigeostrophic\n",
      "idealised\n",
      "aronnax\n",
      "aronnax\n"
     ]
    }
   ],
   "source": [
    "sum_vector_text = np.zeros((300))\n",
    "count = 0\n",
    "for J in range(len(arr)):\n",
    "    texts = arr[J]\n",
    "    texts = texts\n",
    "    texts = texts.replace('-\\\\n','')\n",
    "    texts = texts.replace('-\\n','')\n",
    "    texts = texts.replace('\\\\n',' ')\n",
    "    texts = texts.replace('\\n', ' ')\n",
    "    \n",
    "    texts = [texts]\n",
    "    corpus = [preprocess(text) for text in texts]\n",
    "    \n",
    "    sum_line_vector_text = np.zeros((300))\n",
    "    counter = 0\n",
    "    for i in range(len(corpus[0])):\n",
    "        if corpus[0][i] in model.vocab:\n",
    "            sum_vector_text = sum_vector_text + model.wv[corpus[0][i]]\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            print(corpus[0][i])\n",
    "    average_line_vector_text = sum_line_vector_text/ counter\n",
    "    sum_vector_text = sum_vector_text + average_line_vector_text\n",
    "    count = count + 1\n",
    "average_vector_text = sum_vector_text / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8395d6d4-8124-49e1-9bfc-39440c4088fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70561905,  0.67382278,  0.22724609,  2.64420471, -2.9162509 ,\n",
       "        0.09994202,  1.49788818, -2.67126912,  2.42081223,  2.56471448,\n",
       "       -1.60363525, -2.95984821, -0.52449875,  0.13030643, -2.69560926,\n",
       "        2.47230673, -0.05285287,  3.07062057, -0.96067505, -3.38463669,\n",
       "       -1.06011848, -0.85900192, -2.76929932,  1.35642166, -0.15475273,\n",
       "       -1.50445251, -4.38808002,  3.28292823, -0.79687119, -2.18443146,\n",
       "       -1.20949287, -1.36867599,  0.30220604,  1.25515747, -0.74282722,\n",
       "       -0.93539124,  0.51344433,  0.8677002 ,  2.40998993, -0.09935608,\n",
       "        2.4356308 ,  1.07044868,  1.70902696,  1.29983187, -0.31918468,\n",
       "       -3.12751198, -2.48056574,  0.05177193,  0.25170898,  0.5088542 ,\n",
       "       -0.27563705, -1.73454342, -2.53342295, -2.56156781, -0.03190284,\n",
       "        1.62432098, -0.83691196, -3.5081871 ,  1.63793154, -1.99050941,\n",
       "       -1.25219898,  1.25117111, -2.64893646, -2.58584137,  0.67294693,\n",
       "        0.14880409, -1.4107975 ,  4.74105835, -0.98968964,  0.69989014,\n",
       "        0.05635247, -1.44229431,  3.62614613, -1.85245018, -3.47987366,\n",
       "       -2.31034966,  2.62392578,  1.46707096,  0.11542416,  2.30354614,\n",
       "        0.96154633, -0.23853884,  0.60220375, -0.04615726,  1.05012207,\n",
       "        0.32275829, -2.03669758,  4.02728348,  0.70777588,  2.38945313,\n",
       "        1.7350461 , -2.63361664, -2.80830226,  0.14299731,  0.76142273,\n",
       "       -0.91213074,  0.24881058, -1.76144981,  2.26405029,  0.28448944,\n",
       "        1.20400696, -1.63228149, -1.88868408, -0.25510559, -1.0720932 ,\n",
       "       -0.52349739, -2.42749863,  0.88813705,  2.29285049, -0.97623448,\n",
       "       -1.17239456, -0.83485641, -0.81333466,  0.44014397,  3.00464965,\n",
       "        1.19255028, -0.48621216, -1.41840019,  2.84662037,  0.88792019,\n",
       "       -2.39972982, -0.35998001, -0.61610565,  1.72261581,  1.3825614 ,\n",
       "       -0.06071758, -2.1397049 ,  0.44112186,  1.48289261,  2.58258896,\n",
       "        0.25401535, -0.20744128, -1.62904358,  0.805056  ,  0.23565216,\n",
       "       -0.78478599,  1.49283649, -1.36305628,  0.02472801,  2.3394989 ,\n",
       "        1.00782166, -1.85826416, -0.99646912,  3.01334534,  1.12084599,\n",
       "        0.39034767,  0.02769165, -0.74889679, -0.24798279, -0.37277279,\n",
       "        1.31679993, -1.47655046, -2.7576416 ,  1.57645588,  0.38168793,\n",
       "       -1.3870101 , -1.77550201, -0.16421337, -1.85122795, -0.63656155,\n",
       "        0.43020859,  1.46148987,  0.48909054,  0.46842079, -0.16763077,\n",
       "       -0.25696564,  0.39641553, -1.04797325, -1.20292228, -1.05461903,\n",
       "       -2.86072769, -0.97555351, -2.16476851, -0.61073378,  1.7232811 ,\n",
       "       -0.43240585,  1.60063396, -5.16747475, -3.36809998,  0.57899246,\n",
       "       -4.20884819, -1.86749649, -0.36079102,  0.25741634,  0.39792442,\n",
       "       -0.36141548,  0.4884943 ,  0.76585064,  1.35271606,  1.23113251,\n",
       "       -0.33011322, -0.83614311,  0.23556423, -1.59344969, -2.84977875,\n",
       "        1.45696411,  0.6272707 , -1.99196777, -0.31492472, -3.83882332,\n",
       "        1.49930191,  2.53638077, -1.90034943, -0.75959682, -0.79342403,\n",
       "        0.03613281, -0.19496636, -1.08015251, -0.91769748, -0.41681595,\n",
       "       -1.30569077,  1.42105484, -0.71347151,  2.32860489, -2.75844498,\n",
       "       -0.76800232,  3.37575092,  1.06150131, -2.45378113,  1.59862137,\n",
       "       -0.30909531,  0.16010427, -0.18686218,  0.06997192, -0.65133905,\n",
       "       -0.27135468,  1.20333557,  0.21554718,  1.65139408,  1.226227  ,\n",
       "       -0.19107914,  0.1593792 ,  2.45420074, -0.87112503, -0.38158226,\n",
       "        0.06410446, -0.75063477, -1.81044388,  2.67358932,  0.39646702,\n",
       "        1.50941   , -0.17497864, -0.16646996, -2.86830673, -0.73496246,\n",
       "       -0.45555649, -2.3809761 ,  4.5324892 , -0.21105499, -0.8754158 ,\n",
       "        0.68375092,  1.5092968 , -0.46259613,  0.97566795,  1.44147263,\n",
       "       -2.39249458,  0.27272644, -0.68603668, -1.76844788,  0.08532994,\n",
       "        1.81971207, -1.4916748 , -1.94073257,  0.50330999,  1.25310516,\n",
       "        2.65691996, -0.04753876, -1.67727089, -1.93144379, -1.90006075,\n",
       "       -1.42408142,  2.05742025, -1.25096893,  0.25510559,  1.57835999,\n",
       "       -0.3378643 , -2.81741486, -2.18979416, -1.61821194,  0.13015728,\n",
       "       -1.23748627,  1.26883965,  1.78427162,  0.41787453,  1.34080353,\n",
       "       -1.0940815 , -0.50857105, -0.52690372,  1.08964539,  1.29619379,\n",
       "       -2.95362797,  1.89735916, -1.38489482,  1.02506485,  0.016185  ,\n",
       "        1.7187006 ,  0.44410553, -1.47123566,  0.0972229 ,  0.21500473])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vector_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2cf9f05-720d-4eb8-8ed5-b8b5904c86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mso_font_pitch', 0.7048326730728149),\n",
       " ('By_Kat_Zeman', 0.693383514881134),\n",
       " ('DIRECTORS_OF_CAPITAL_CORP.', 0.6915027499198914),\n",
       " ('By_Elise_Viebeck', 0.6871206760406494),\n",
       " ('By_Jonas_Elmerraji', 0.6867182850837708),\n",
       " ('By_Laurelle_Gilbert', 0.6848405599594116),\n",
       " ('By_Miriam_Reimer', 0.6836596131324768),\n",
       " ('By_JANIS_CARR', 0.6830937266349792),\n",
       " ('Horses_previewed', 0.6806297898292542),\n",
       " ('By_Laurie_Kulikowski', 0.6799852848052979),\n",
       " ('By_Joseph_Woelfel', 0.6780015826225281),\n",
       " ('BY_VINCENT_MAO', 0.6707745790481567),\n",
       " ('By_STEPHEN_WILLIS', 0.6701783537864685),\n",
       " ('SCOTT_BAIR_Staff_Writer', 0.6695973873138428),\n",
       " ('Nambu_theories_permeate', 0.6651671528816223),\n",
       " ('By_Bill_Esbrook', 0.6635015606880188),\n",
       " ('By_LEON_HALE', 0.6623695492744446),\n",
       " ('BY_LEROY_SIGMAN', 0.6620042324066162),\n",
       " (\"JW_'S_SALOON\", 0.6610624194145203),\n",
       " ('By_Christine_Fenno', 0.6609067320823669)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(average_vector_text, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f185261e-6e64-4489-b188-1d15c6170b14",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/JOSS PROJECT/JOSS_Reviewer_Matcher/Data/JOSS Table Test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/69/wyv1g7hn08z6pv25vg868lww0000gn/T/ipykernel_15550/834583475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_reviewers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Documents/JOSS PROJECT/JOSS_Reviewer_Matcher/Data/JOSS Table Test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/JOSS PROJECT/JOSS_Reviewer_Matcher/Data/JOSS Table Test.csv'"
     ]
    }
   ],
   "source": [
    "df_reviewers = pd.read_csv('Documents/JOSS PROJECT/JOSS_Reviewer_Matcher/Data/JOSS Table Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc24572-6697-4aa1-b153-48cf745202f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetReviewerSample_W2V(paper_vec, df_reviewers=df_reviewers):\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_cosine_sims = []\n",
    "    for j in range(df_reviewers.shape[0]-1):\n",
    "        if pd.isna(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing']) == False:\n",
    "            reviewer_interests = df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing'].lower()\n",
    "            reviewer_interests.replace('/',' ')\n",
    "            reviewer_corpus = [preprocess(reviewer_interests)]\n",
    "            if bool(reviewer_corpus[0]) == True:\n",
    "        #print(reviewer_corpus)\n",
    "                sum_vector_text = np.zeros((300))\n",
    "                counter = 0\n",
    "                for i in range(len(reviewer_corpus[0])):\n",
    "                    if reviewer_corpus[0][i] in model.vocab:\n",
    "                        sum_vector_text = sum_vector_text + model.wv[reviewer_corpus[0][i]]\n",
    "                        counter = counter + 1\n",
    "                    else:\n",
    "                        print(reviewer_corpus[0][i])\n",
    "                if counter > 0:\n",
    "                    average_Reviewer_vector_text = sum_vector_text/ counter\n",
    "                    all_usernames.append(df_reviewers.username.iloc[j+1])\n",
    "                    all_domains.append(reviewer_interests)\n",
    "                    all_cosine_sims.append(cosine_similarity(np.array([paper_vec]), np.array([average_Reviewer_vector_text]))[0,0])\n",
    "    return np.array(all_usernames), np.array(all_domains), np.array(all_cosine_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38360ecc-ad18-49ae-a2cc-413703da6dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GetReviewerSample_W2V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/69/wyv1g7hn08z6pv25vg868lww0000gn/T/ipykernel_15550/1894739717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_usernames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_domains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_cosine_sims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetReviewerSample_W2V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_vector_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'GetReviewerSample_W2V' is not defined"
     ]
    }
   ],
   "source": [
    "all_usernames, all_domains, all_cosine_sims = GetReviewerSample_W2V(average_vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5dbc2e-295b-4039-add7-133358811731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TopReviewers(number=5, all_usernames=all_usernames, all_domains=all_domains, all_cosine_sims=all_cosine_sims):\n",
    "    message = 'Hello.\\n I have found ' +str(number) + ' possible reviewers for this paper.'+ '\\n\\n'\n",
    "    for J in range(number):\n",
    "        index = np.argsort(all_cosine_sims)[-1-J]\n",
    "        #print(index)\n",
    "        ps = 'I believe '+ str(all_usernames[index]) + ' will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of ' + str(all_cosine_sims[index])[:6] + '. This reviewers domain interests are ' + str(all_domains[index].replace('\\n', ','))\n",
    "        message = message + ps + '\\n\\n'\n",
    "    print(message)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40393d39-e466-4f08-9676-74bb08927b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopReviewers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e43106-4009-4f13-9892-a7008c4e33e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
