{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162e2783-1e73-4e84-9a6d-98becf60f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a507d08-65d6-4aa0-9ff3-3734503c039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JOSS_PDF_Cleaner import Clean_PDF\n",
    "import re\n",
    "from termcolor import colored\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8804f7bd-81aa-4856-92f8-a38934dbab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "#import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk \n",
    "#nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac7bdc7-55e9-482d-b60e-d869b88bd8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sunilmcesh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#from Master_Methods import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "#import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.probability import FreqDist\n",
    "from JOSS_PDF_Cleaner import Clean_PDF\n",
    "import re\n",
    "from termcolor import colored\n",
    "import spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7010c21-b0e3-40e2-821b-a440f0a7f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7af63a-561a-4afb-82c4-3047dacc9529",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66357afc-9d23-494b-a1ce-4f7f12682887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zenodo.org/record/3631674#.YeglfP7P2Uk\n",
    "df = pd.read_csv('/Volumes/Seagate Backup Plus Drive/JOSS Project/wiki_tfidf_terms.csv')\n",
    "df_reviewers = pd.read_csv('../JOSS_Reviewer_Matcher/Data/JOSS Table Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbee41-a44b-44df-892b-6125d96410b2",
   "metadata": {},
   "source": [
    "# Select Paper to find Reviewers for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6f2c8b7-a13b-4048-ad02-38feb953934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/joss-papers-master/joss.01144/10.21105.joss.01144.pdf\n"
     ]
    }
   ],
   "source": [
    "#PAPER_OF_INTEREST_FNAME  = glob.glob('/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/*/*/*.pdf')\n",
    "#K = 260\n",
    "#Paper_interest = PAPER_OF_INTEREST_FNAME[K] # Replace with path to paper of interest\n",
    "Paper_interest = '/Volumes/Seagate Backup Plus Drive/JOSS Project/joss-papers-master/joss-papers-master/joss.01144/10.21105.joss.01144.pdf'\n",
    "print(Paper_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9fce1-cbaf-4cde-9811-32a0ff76ad3e",
   "metadata": {},
   "source": [
    "# Printing Paper of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8da8f57f-0a85-42ad-98d5-adc31af6ac8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MakeGreenRedText(Paper_interest, printer=True):\n",
    "    texts = ''\n",
    "    arr = []\n",
    "    from pdfminer.high_level import extract_pages\n",
    "    from pdfminer.layout import LTTextContainer\n",
    "    for page_layout in extract_pages(Paper_interest):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                score = Clean_PDF(element.get_text().lower())\n",
    "            #print(score)\n",
    "                if score == 0:\n",
    "                    if printer == True:\n",
    "                        print(colored(element.get_text().lower(), 'green'))\n",
    "                    arr.append(element.get_text())\n",
    "                    texts = texts  + element.get_text() + ' '\n",
    "                else:\n",
    "                    if printer == True:\n",
    "                        print(colored(element.get_text().lower(), 'red'))\n",
    "            #arr.append(element.get_text())\n",
    "            #texts = texts  + element.get_text() + ' '\n",
    "    arr = np.array(arr)\n",
    "    return texts, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0ae3840-553a-4cf6-9b1c-cc4db3241fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mdoi: 10.21105/joss.01144\n",
      "\u001b[0m\n",
      "\u001b[31msoftware\n",
      "\u001b[0m\n",
      "\u001b[31m• review\n",
      "• repository\n",
      "• archive\n",
      "\u001b[0m\n",
      "\u001b[31msubmitted: 27 november 2018\n",
      "published: 26 march 2019\n",
      "\u001b[0m\n",
      "\u001b[31mlicense\n",
      "authors of papers retain copy-\n",
      "right and release the work un-\n",
      "der a creative commons attri-\n",
      "bution 4.0 international license\n",
      "(cc-by).\n",
      "\u001b[0m\n",
      "\u001b[32mvcftoolz: a python package for comparing and evaluating\n",
      "variant call format files.\n",
      "\u001b[0m\n",
      "\u001b[31msteve davis1\n",
      "\u001b[0m\n",
      "\u001b[31m1 u.s. food and drug administration\n",
      "\u001b[0m\n",
      "\u001b[31msummary and need statement\n",
      "\u001b[0m\n",
      "\u001b[32mthe analysis of next-generation sequence data often involves variant calling – the process\n",
      "of identifying differences between genomes. the standard output file format of variant\n",
      "callers is the variant call format (vcf) (https://github.com/samtools/hts-specs).\n",
      "\u001b[0m\n",
      "\u001b[32mresearchers need to view and compare vcf files when comparing the behavior of different\n",
      "variant calling algorithms (and even the same algorithm with different parameters). ad-\n",
      "ditionally, the performance of a variant calling algorithm can be evaluated by comparing\n",
      "against a known truth vcf dataset.\n",
      "\u001b[0m\n",
      "\u001b[31mhere, we present vcftoolz, software to facilitate comparing and evaluating the variant\n",
      "calls in vcf files. the core functionality of vcftoolz is the capability to compare two\n",
      "or more vcf files, producing a report, venn diagrams, and a spreadsheet identifying the\n",
      "concordance between the vcf files. the artifacts produced by vcftoolz are not available\n",
      "from other tools.\n",
      "\u001b[0m\n",
      "\u001b[32mthe vcftoolz software is designed to work with bacterial variant files. it has been tested\n",
      "in a 3-way comparison of vcf files, with each file having 200 samples and 500 snps per\n",
      "sample for a total of 100,000 variants in each file.\n",
      "\u001b[0m\n",
      "\u001b[32mrelated research\n",
      "\u001b[0m\n",
      "\u001b[32mthe vcftoolz software is being used as part of an ongoing effort to compare and evalu-\n",
      "ate the variant callers used by multiple government agencies involved in the analysis of\n",
      "pathogenic organisms of interest to food safety. in this effort, we use multiple variant\n",
      "callers to construct vcf files from food-borne pathogens. the vcftoolz software iden-\n",
      "tifies the concordance between the vcf files produced by the alternative variant callers\n",
      "and facilitates algorithm improvements.\n",
      "\u001b[0m\n",
      "\u001b[32mprior related work\n",
      "\u001b[0m\n",
      "\u001b[31mthe rtg tools package (cleary et al., 2015) has advanced capabilities to compare vcf\n",
      "files containing complex variants, but does not support vcf files with multiple samples\n",
      "per file.\n",
      "\u001b[0m\n",
      "\u001b[31mthe bcftools (clarke et al., n.d.) package has the capability to create intersections,\n",
      "unions and complements of vcf files, as well as other useful tools for working with vcf\n",
      "files.\n",
      "\u001b[0m\n",
      "\u001b[31mdavis, (2019). vcftoolz: a python package for comparing and evaluating variant call format files.. journal of open source software, 4(35),\n",
      "1144. https://doi.org/10.21105/joss.01144\n",
      "\u001b[0m\n",
      "\u001b[31m1\n",
      "\u001b[0m\n",
      "\u001b[31mthe vcftools (danecek et al., 2011) package has the capability to calculate differences\n",
      "between vcf files, among other functions.\n",
      "\u001b[0m\n",
      "\u001b[32mdocumentation: https://vcftoolz.readthedocs.io/en/latest/readme.html\n",
      "\u001b[0m\n",
      "\u001b[32msource code: https://github.com/cfsan-biostatistics/vcftoolz\n",
      "\u001b[0m\n",
      "\u001b[32mpypi distribution: https://pypi.python.org/pypi/vcftoolz\n",
      "\u001b[0m\n",
      "\u001b[31mlinks\n",
      "\u001b[0m\n",
      "\u001b[31mreferences\n",
      "\u001b[0m\n",
      "\u001b[31mclarke, n., collier, t., danecek, p., herrero, j., kretzschmar, w., li, h., mccarthy,\n",
      "s., et al. (n.d.). bcftools. retrieved november 26, 2018, from https://github.com/\n",
      "samtools/bcftools\n",
      "\u001b[0m\n",
      "\u001b[31mcleary, j. g., braithwaite, r., gaastra, k., hilbush, b. s., inglis, s., irvine, s. a., jackson,\n",
      "a., et al. (2015). comparing variant call files for performance benchmarking of next-\n",
      "generation sequencing variant calling pipelines. biorxiv, 023754. doi:10.1101/023754\n",
      "\u001b[0m\n",
      "\u001b[31mdanecek, p., auton, a., abecasis, g., albers, c. a., banks, e., depristo, m. a., hand-\n",
      "saker, r. e., et al. (2011). the variant call format and vcftools. bioinformatics, 27 (15),\n",
      "2156–2158. doi:10.1093/bioinformatics/btr330\n",
      "\u001b[0m\n",
      "\u001b[31mdavis, (2019). vcftoolz: a python package for comparing and evaluating variant call format files.. journal of open source software, 4(35),\n",
      "1144. https://doi.org/10.21105/joss.01144\n",
      "\u001b[0m\n",
      "\u001b[31m2\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "texts, arr = MakeGreenRedText(Paper_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113e5dc-08a7-4d15-9cc2-8e6b4362c257",
   "metadata": {},
   "source": [
    "# All Functions\n",
    "Hidden for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f4b5ccb6-ef6c-4ddb-a2a8-ea381623715d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################# Idea 1 #####################\n",
    "def Get_Lemma_Words(POI_PDF):\n",
    "  text = str(POI_PDF)\n",
    "  text2 = text.split()\n",
    "  words_no_punc = []\n",
    "\n",
    "  for w in text2:\n",
    "    if w.isalpha():\n",
    "      words_no_punc.append(w.lower())\n",
    "  from nltk.corpus import stopwords\n",
    "  stopwords = stopwords.words('english')  \n",
    "  clean_words = []\n",
    "  for w in words_no_punc:\n",
    "    if w not in stopwords:\n",
    "      clean_words.append(w)\n",
    "  clean_words_arr = ''\n",
    "  for i in range(len(clean_words)):\n",
    "    clean_words_arr = clean_words_arr + ' ' + str(clean_words[i])\n",
    "\n",
    "  string_for_lemmatizing = clean_words_arr\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  words_2 = word_tokenize(string_for_lemmatizing)\n",
    "  lemmatized_words = [lemmatizer.lemmatize(word) for word in words_2]\n",
    "\n",
    "  lemmatized_words_arr = ''\n",
    "  for i in range(len(lemmatized_words)):\n",
    "    lemmatized_words_arr = lemmatized_words_arr + ' ' + str(lemmatized_words[i])\n",
    "  words = word_tokenize(lemmatized_words_arr)\n",
    "\n",
    "  return words\n",
    "\n",
    "def Get_reviewer_sample_tf(Paper_interest, df_reviewers=df_reviewers,num_suggestions=5, num_top20=20):\n",
    "    POI_PDF = [extract_text(Paper_interest)]\n",
    "    text = str(POI_PDF)\n",
    "    words =  Get_Lemma_Words(POI_PDF)\n",
    "    #print(len(words))\n",
    "    fdist = FreqDist(words)\n",
    "    X = np.array(fdist.most_common())\n",
    "    top20_tf = X[:num_top20,0]\n",
    "    match_arr = Compare_topics(top20_tf, df_reviewers)\n",
    "    top5_reviewers = np.argsort(match_arr)[-num_suggestions:]\n",
    "\n",
    "    \n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_num_matched_words = []\n",
    "    all_matched_words = []\n",
    "    for i in range(num_suggestions):\n",
    "      K = -1*(i+1)\n",
    "      index = top5_reviewers[K]\n",
    "      #print(i)\n",
    "      t =df_reviewers.iloc[index+1]['Domains/topic areas you are comfortable reviewing'].lower()\n",
    "      \n",
    "      all_usernames.append(df_reviewers.username.iloc[index+1])\n",
    "      all_domains.append(t)\n",
    "      all_num_matched_words.append(match_arr[index])\n",
    "\n",
    "      uniarr = Split_columns(t)\n",
    "      matched_words = []\n",
    "      #print(uniarr)\n",
    "      for j in range(len(uniarr)):\n",
    "        for k in range(len(top20_tf)):\n",
    "          if uniarr[j] == top20_tf[k]:\n",
    "            matched_words.append(uniarr[j])\n",
    "      all_matched_words.append(matched_words)\n",
    "\n",
    "    #df_reviewers.username.iloc[+1]\n",
    "\n",
    "    return all_usernames, all_domains, all_num_matched_words, all_matched_words\n",
    "\n",
    "def Compare_topics(top20, df_reviewers):\n",
    "  length = df_reviewers.shape[0] - 1\n",
    "  match_arr = np.zeros(length)\n",
    "  for i in range(length):\n",
    "    if pd.isna(df_reviewers['Domains/topic areas you are comfortable reviewing'].str.lower().values[1+i]) == False:\n",
    "      t = df_reviewers['Domains/topic areas you are comfortable reviewing'].str.lower().values[1+i]\n",
    "      #print(i)\n",
    "      uniarr = Split_columns(t)\n",
    "      for j in range(len(uniarr)):\n",
    "        for k in range(len(top20)):\n",
    "          if uniarr[j] == top20[k]:\n",
    "            match_arr[i] = match_arr[i] + 1\n",
    "  return match_arr\n",
    "\n",
    "def Split_columns(t):\n",
    "  txt = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in t]).split())\n",
    "  sol1 = np.char.split(txt, ' ')\n",
    "  txt_arr  = array_of_lists_to_array(sol1)\n",
    "  uniarr = np.unique(txt_arr)\n",
    "  return uniarr\n",
    "\n",
    "def array_of_lists_to_array(arr):\n",
    "    return np.apply_along_axis(lambda a: np.array(a[0]), -1, arr[..., None])\n",
    "\n",
    "\n",
    "def summatation_bot_tf(all_usernames, all_domains, all_num_matched_words, all_matched_words):\n",
    "  length = len(all_usernames)\n",
    "  message = 'Hello. \\nI have found ' + str(length) + ' possible reviewers for this paper.' +'\\n\\n'\n",
    "  for i in range(length):\n",
    "    ps = 'I believe ' + colored(all_usernames[i], 'green') + ' will make a good reviewer for this paper because they have matched ' + colored(str(int(all_num_matched_words[i])), 'blue') +  ' words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are ' + colored(str(all_matched_words[i]), 'blue') +'.\\nFrom their topics domain: ' + colored(str(all_domains[i].replace('\\n', ', ')), 'red') +'.\\n'\n",
    "    message = message + ps + '\\n'\n",
    "  print(message)\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 2 #####################\n",
    "\n",
    "# Idea 2\n",
    "\n",
    "def Get_reviewer_sample_tf_idf(Paper_interest, df=df, df_reviewers=df_reviewers, num_suggestions=5, num_top20=20):\n",
    "    POI_PDF = [extract_text(Paper_interest)]\n",
    "    text = str(POI_PDF)\n",
    "    words = Get_Lemma_Words(POI_PDF)\n",
    "    #print(len(words))\n",
    "    fdist = FreqDist(words)\n",
    "    X = np.array(fdist.most_common())\n",
    "    tf_idf_arr_names, tf_idf_arr_floats = determine_wiki_td_idf(X, df=df)\n",
    "    #print('determined wiki')\n",
    "    num_arr = np.array(tf_idf_arr_floats)\n",
    "    tf_idf_arr_names_arr = np.array(tf_idf_arr_names)\n",
    "    top20_tf_idf = tf_idf_arr_names_arr[np.argsort(num_arr)[:20]]\n",
    "    match_arr = Compare_topics(top20_tf_idf, df_reviewers)\n",
    "    top5_reviewers = np.argsort(match_arr)[-num_suggestions:]\n",
    "    \n",
    "    \n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_num_matched_words = []\n",
    "    all_matched_words = []\n",
    "    for i in range(num_suggestions):\n",
    "      K = -1*(i+1)\n",
    "      index = top5_reviewers[K]\n",
    "      #print(i)\n",
    "      t =df_reviewers.iloc[index+1]['Domains/topic areas you are comfortable reviewing'].lower()\n",
    "      \n",
    "      all_usernames.append(df_reviewers.username.iloc[index+1])\n",
    "      all_domains.append(t)\n",
    "      all_num_matched_words.append(match_arr[index])\n",
    "\n",
    "      uniarr = Split_columns(t)\n",
    "      matched_words = []\n",
    "      #print(uniarr)\n",
    "      for j in range(len(uniarr)):\n",
    "        for k in range(len(top20_tf_idf)):\n",
    "          if uniarr[j] == top20_tf_idf[k]:\n",
    "            matched_words.append(uniarr[j])\n",
    "      all_matched_words.append(matched_words)\n",
    "\n",
    "    #df_reviewers.username.iloc[+1]\n",
    "\n",
    "    return all_usernames, all_domains, all_num_matched_words, all_matched_words\n",
    "\n",
    "def determine_wiki_td_idf(x, df=df):\n",
    "    tf_idf_arr_names = []\n",
    "    tf_idf_arr_floats = []\n",
    "    for i in range(len(x)):\n",
    "        if df[df['token'] ==x[i][0]].frequency.empty == False:\n",
    "            wiki_tf = df[df['token'] ==x[i][0]].frequency.values[0]\n",
    "            doc_tf = int(x[i][1])\n",
    "            tf_idf = np.log(wiki_tf/doc_tf)\n",
    "            tf_idf_arr_names.append(x[i][0])\n",
    "            tf_idf_arr_floats.append(tf_idf)\n",
    "    return tf_idf_arr_names, tf_idf_arr_floats\n",
    "\n",
    "def summatation_bot_tf_idf(all_usernames, all_domains, all_num_matched_words, all_matched_words):\n",
    "  length = len(all_usernames)\n",
    "  message = 'Hello. \\nI have found ' + str(length) + ' possible reviewers for this paper.' +'\\n\\n'\n",
    "  for i in range(length):\n",
    "    ps = 'I believe ' + colored(all_usernames[i], 'green') + ' will make a good reviewer for this paper because they have matched ' + colored(str(int(all_num_matched_words[i])), 'blue') +  ' words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are ' + colored(str(all_matched_words[i]), 'blue') +'.\\nFrom their topics domain: ' + colored(str(all_domains[i].replace('\\n', ', ')), 'red') +'.\\n'\n",
    "    message = message + ps + '\\n'\n",
    "  print(message)\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Gensim ####################\n",
    "\n",
    "def preprocess_gensim(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc\n",
    "\n",
    "def W2V_Gensim_Processing(texts,model, print_outside_corpus=True):\n",
    "    t = texts\n",
    "    t = t.replace('-\\\\n','')\n",
    "    t = t.replace('-\\n','')\n",
    "    t = t.replace('\\\\n',' ')\n",
    "    t = t.replace('\\n', ' ')\n",
    "    texts = t\n",
    "    #print(t)\n",
    "\n",
    "    #download('punkt') #tokenizer, run once\n",
    "    #download('stopwords') #stopwords dictionary, run once\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    texts = [texts]\n",
    "    corpus = [preprocess_gensim(text) for text in texts]\n",
    "\n",
    "    sum_vector_text = np.zeros((300))\n",
    "    counter = 0\n",
    "    for i in range(len(corpus[0])):\n",
    "        if corpus[0][i] in model.vocab:\n",
    "            sum_vector_text = sum_vector_text + model.wv[corpus[0][i]]\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            if print_outside_corpus == True:\n",
    "                print(corpus[0][i])\n",
    "    average_vector_text = sum_vector_text/ counter\n",
    "    return average_vector_text\n",
    "\n",
    "\n",
    "def GetReviewerSample_W2V_Gensim(paper_vec, df_reviewers=df_reviewers):\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_cosine_sims = []\n",
    "    for j in range(df_reviewers.shape[0]-1):\n",
    "        if pd.isna(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing']) == False:\n",
    "            reviewer_interests = df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing'].lower()\n",
    "            reviewer_interests.replace('/',' ')\n",
    "            reviewer_corpus = [preprocess_gensim(reviewer_interests)]\n",
    "            if bool(reviewer_corpus[0]) == True:\n",
    "        #print(reviewer_corpus)\n",
    "                sum_vector_text = np.zeros((300))\n",
    "                counter = 0\n",
    "                for i in range(len(reviewer_corpus[0])):\n",
    "                    if reviewer_corpus[0][i] in model.vocab:\n",
    "                        sum_vector_text = sum_vector_text + model.wv[reviewer_corpus[0][i]]\n",
    "                        counter = counter + 1\n",
    "                    else:\n",
    "                        print(reviewer_corpus[0][i])\n",
    "                if counter > 0:\n",
    "                    average_Reviewer_vector_text = sum_vector_text/ counter\n",
    "                    all_usernames.append(df_reviewers.username.iloc[j+1])\n",
    "                    all_domains.append(reviewer_interests)\n",
    "                    all_cosine_sims.append(cosine_similarity(np.array([paper_vec]), np.array([average_Reviewer_vector_text]))[0,0])\n",
    "    return np.array(all_usernames), np.array(all_domains), np.array(all_cosine_sims)\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 3 TF Gensim ####################\n",
    "\n",
    "\n",
    "def Get_Top_Words_tf(Paper_interest, df_reviewers=df_reviewers,num_suggestions=5, num_top20=20):\n",
    "    POI_PDF = [extract_text(Paper_interest)]\n",
    "    text = str(POI_PDF)\n",
    "    words =  Get_Lemma_Words(POI_PDF)\n",
    "    #print(len(words))\n",
    "    fdist = FreqDist(words)\n",
    "    X = np.array(fdist.most_common())\n",
    "    top20_tf = X[:num_top20,0]\n",
    "\n",
    "    #df_reviewers.username.iloc[+1]\n",
    "\n",
    "    return top20_tf\n",
    "\n",
    "\n",
    "\n",
    "def Split_columns(t):\n",
    "  txt = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in t]).split())\n",
    "  sol1 = np.char.split(txt, ' ')\n",
    "  txt_arr  = array_of_lists_to_array(sol1)\n",
    "  uniarr = np.unique(txt_arr)\n",
    "  return uniarr\n",
    "\n",
    "\n",
    "def summatation_bot(all_usernames, all_domains, all_num_matched_words, all_matched_words):\n",
    "  length = len(all_usernames)\n",
    "  message = 'Hello. \\nI have found ' + str(length) + ' possible reviewers for this paper.' +'\\n\\n'\n",
    "  for i in range(length):\n",
    "    ps = 'I believe ' + all_usernames[i] + ' will make a good reviewer for this paper because they have matched ' + str(int(all_num_matched_words[i])) +  ' words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are ' + str(all_matched_words[i]) +'.\\nFrom their topics domain: ' + str(all_domains[i].replace('\\n', ', ')) +'.\\n'\n",
    "    message = message + ps + '\\n'\n",
    "  print(message)\n",
    "\n",
    "\n",
    "\n",
    "def W2V_Gensim_Processing_tf(top_arr, model, print_outside_corpus=True):\n",
    "    texts = ''\n",
    "    for i in range(len(top_arr)):\n",
    "        texts = texts + top_arr[i] + ' ' \n",
    "    #print(t)\n",
    "\n",
    "    #download('punkt') #tokenizer, run once\n",
    "    #download('stopwords') #stopwords dictionary, run once\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    texts = [texts]\n",
    "    corpus = [preprocess_gensim(text) for text in texts]\n",
    "\n",
    "    sum_vector_text = np.zeros((300))\n",
    "    counter = 0\n",
    "    for i in range(len(corpus[0])):\n",
    "        if corpus[0][i] in model.vocab:\n",
    "            sum_vector_text = sum_vector_text + model.wv[corpus[0][i]]\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            if print_outside_corpus == True:\n",
    "                print(corpus[0][i])\n",
    "    average_vector_text = sum_vector_text/ counter\n",
    "    return average_vector_text\n",
    "\n",
    "    \n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 3 TF-IDF Gensim ####################\n",
    "\n",
    "def Get_Top_Words_tf_idf(Paper_interest, df=df, df_reviewers=df_reviewers, num_suggestions=5, num_top20=20):\n",
    "    POI_PDF = [extract_text(Paper_interest)]\n",
    "    text = str(POI_PDF)\n",
    "    words = Get_Lemma_Words(POI_PDF)\n",
    "    #print(len(words))\n",
    "    fdist = FreqDist(words)\n",
    "    X = np.array(fdist.most_common())\n",
    "    tf_idf_arr_names, tf_idf_arr_floats = determine_wiki_td_idf(X, df=df)\n",
    "    #print('determined wiki')\n",
    "    num_arr = np.array(tf_idf_arr_floats)\n",
    "    tf_idf_arr_names_arr = np.array(tf_idf_arr_names)\n",
    "    top20_tf_idf = tf_idf_arr_names_arr[np.argsort(num_arr)[:num_top20]]\n",
    "    return top20_tf_idf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 4 Gensim ####################\n",
    "\n",
    "def TopReviewers_W2V_Gensim(number, all_usernames, all_domains, all_cosine_sims):\n",
    "    message = 'Hello.\\n I have found ' +str(number) + ' possible reviewers for this paper.'+ '\\n\\n'\n",
    "    for J in range(number):\n",
    "        index = np.argsort(all_cosine_sims)[-1-J]\n",
    "        #print(index)\n",
    "        ps = 'I believe '+ colored(str(all_usernames[index]), 'green') + ' will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of ' + colored(str(all_cosine_sims[index])[:6], 'blue') + '. This reviewers domain interests are ' + colored(str(all_domains[index].replace('\\n', ',')), 'red')\n",
    "        message = message + ps + '\\n\\n'\n",
    "    print(message)    \n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 6 Gensim ####################\n",
    "\n",
    "def MakingPaperVector_Idea6_Gensim(arr, model, printer=True):\n",
    "    sum_vector_text = np.zeros((300))\n",
    "    count = 0\n",
    "    for J in range(len(arr)):\n",
    "        texts = arr[J]\n",
    "        texts = texts\n",
    "        texts = texts.replace('-\\\\n','')\n",
    "        texts = texts.replace('-\\n','')\n",
    "        texts = texts.replace('\\\\n',' ')\n",
    "        texts = texts.replace('\\n', ' ')\n",
    "    \n",
    "        texts = [texts]\n",
    "        corpus = [preprocess_gensim(text) for text in texts]\n",
    "    \n",
    "        sum_line_vector_text = np.zeros((300))\n",
    "        counter = 0\n",
    "        for i in range(len(corpus[0])):\n",
    "            if corpus[0][i] in model.vocab:\n",
    "                sum_vector_text = sum_vector_text + model.wv[corpus[0][i]]\n",
    "                counter = counter + 1\n",
    "            else:\n",
    "                if printer == True:\n",
    "                    print(corpus[0][i])\n",
    "        average_line_vector_text = sum_line_vector_text/ counter\n",
    "        sum_vector_text = sum_vector_text + average_line_vector_text\n",
    "        count = count + 1\n",
    "    average_vector_text = sum_vector_text / count\n",
    "    \n",
    "    return average_vector_text\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# spaCy ####################\n",
    "\n",
    "def GetReviewer_Vectors_spacy(model,df_reviewers=df_reviewers):\n",
    "    reviewer_vectors = np.zeros(((df_reviewers.shape[0]-1),300))\n",
    "    for i in range(df_reviewers.shape[0]-1):\n",
    "        #if i%10 == 0:\n",
    "        #    print(i)\n",
    "        if pd.isna(df_reviewers['Domains/topic areas you are comfortable reviewing'].iloc[1:].values[i]) == False:\n",
    "            review_text = df_reviewers['Domains/topic areas you are comfortable reviewing'].iloc[1:].values[i].lower()\n",
    "            review_text = review_text.replace('-\\\\n','')\n",
    "            review_text = review_text.replace('\\\\n',' ')\n",
    "            review_text = review_text.replace('\\n', ' ')\n",
    "        \n",
    "            review_arr = []\n",
    "            for token in model(review_text):\n",
    "                if token.is_alpha == True:\n",
    "                    if token.is_stop == False:\n",
    "                        review_arr.append(str(token.lemma_).lower())\n",
    "            review_arr = np.array(review_arr)\n",
    "        \n",
    "            review_str = ''\n",
    "            for j in np.unique(review_arr):\n",
    "                review_str = review_str + j +' '\n",
    "        \n",
    "        #print(model(review_str).vector.shape)\n",
    "        #print(reviewer_vectors.shape)\n",
    "            reviewer_vectors[i] = model(review_str).vector\n",
    "    \n",
    "    return reviewer_vectors\n",
    "\n",
    "def GetCosineSims_spacy(doc_vec, review_vec, df_reviewers=df_reviewers):\n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_cosine_sims = []\n",
    "    for j in range(len(review_vec)):\n",
    "        if pd.isna(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing']) == False:\n",
    "            all_cosine_sims.append(cosine_similarity(np.array([doc_vec]), np.array([review_vec[j]]))[0,0])\n",
    "            all_domains.append(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing'].lower())\n",
    "            all_usernames.append(df_reviewers.iloc[j+1].username)\n",
    "    all_usernames= np.array(all_usernames)\n",
    "    all_domains= np.array(all_domains)\n",
    "    all_cosine_sims= np.array(all_cosine_sims)\n",
    "    \n",
    "    return all_usernames, all_domains, all_cosine_sims\n",
    "\n",
    "#def TopReviewers_spacy(number=5, all_usernames=all_usernames, all_domains=all_domains, all_cosine_sims=all_cosine_sims):\n",
    "def TopReviewers_spacy(number, all_usernames, all_domains, all_cosine_sims):\n",
    "    message = 'Hello.\\n I have found ' +str(number) + ' possible reviewers for this paper.'+ '\\n\\n'\n",
    "    for J in range(number):\n",
    "        index = np.argsort(all_cosine_sims)[-1-J]\n",
    "        #print(index)\n",
    "        ps = 'I believe '+ colored(str(all_usernames[index]), 'green') + ' will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of ' + colored(str(all_cosine_sims[index])[:6], 'blue') + '. This reviewers domain interests are ' + colored(str(all_domains[index].replace('\\n', ',')), 'red')\n",
    "        message = message + ps + '\\n\\n'\n",
    "    print(message)        \n",
    "    \n",
    "    \n",
    "def W2V_spaCy_Processing(texts, green_text=True, lemma=True, unique=True):\n",
    "    texts = texts.replace('-\\\\n','')\n",
    "    texts = texts.replace('-\\n','')\n",
    "    texts = texts.replace('\\\\n',' ')\n",
    "    texts = texts.replace('\\n', ' ')\n",
    "    \n",
    "    model = spacy.load('en_core_web_lg')\n",
    "    reviewer_vectors = GetReviewer_Vectors_spacy(model)\n",
    "    \n",
    "    # Only Green Text: \n",
    "    if green_text == True:\n",
    "        print('### Only Green Text - No Other Preprocessing ###')\n",
    "        all_usernames, all_domains, all_cosine_sims = GetCosineSims_spacy(model(texts).vector, reviewer_vectors)\n",
    "        TopReviewers_spacy(5, all_usernames, all_domains, all_cosine_sims)\n",
    "        \n",
    "    doc = model(texts)\n",
    "    doc_arr = []\n",
    "    for token in doc:\n",
    "        if token.is_alpha == True:\n",
    "            if token.is_stop == False:\n",
    "                doc_arr.append(str(token.lemma_).lower())\n",
    "    doc_arr = np.array(doc_arr)\n",
    "    \n",
    "    doc_arr_mod = ''\n",
    "    for i in doc_arr:\n",
    "        doc_arr_mod = doc_arr_mod + i +' '\n",
    "    \n",
    "    # Green Text and Lemmasation\n",
    "    if lemma == True:\n",
    "        print('### Green Text & Lemmasation ###')\n",
    "        all_usernames2, all_domains2, all_cosine_sims2 = GetCosineSims_spacy(model(doc_arr_mod).vector, reviewer_vectors)\n",
    "        TopReviewers_spacy(5, all_usernames2, all_domains2, all_cosine_sims2)\n",
    "        \n",
    "    if unique == True:\n",
    "        print('### Green Text & Lemmasation & Unique Words ###')\n",
    "        doc_str = ''\n",
    "        for i in np.unique(doc_arr):\n",
    "            doc_str = doc_str + i +' '\n",
    "        all_usernames3, all_domains3, all_cosine_sims3 = GetCosineSims_spacy(model(doc_str).vector, reviewer_vectors)\n",
    "        TopReviewers_spacy(5,all_usernames3, all_domains3, all_cosine_sims3)\n",
    "        \n",
    "def GetReviewer_Vectors(df_reviewers=df_reviewers):\n",
    "    reviewer_vectors = np.zeros(((df_reviewers.shape[0]-1),300))\n",
    "    for i in range(df_reviewers.shape[0]-1):\n",
    "        #if i%10 == 0:\n",
    "        #    print(i)\n",
    "        if pd.isna(df_reviewers['Domains/topic areas you are comfortable reviewing'].iloc[1:].values[i]) == False:\n",
    "            review_text = df_reviewers['Domains/topic areas you are comfortable reviewing'].iloc[1:].values[i].lower()\n",
    "            review_text = review_text.replace('-\\\\n','')\n",
    "            review_text = review_text.replace('\\\\n',' ')\n",
    "            review_text = review_text.replace('\\n', ' ')\n",
    "        \n",
    "            review_arr = []\n",
    "            for token in model(review_text):\n",
    "                if token.is_alpha == True:\n",
    "                    if token.is_stop == False:\n",
    "                        review_arr.append(str(token.lemma_).lower())\n",
    "            review_arr = np.array(review_arr)\n",
    "        \n",
    "            review_str = ''\n",
    "            for j in np.unique(review_arr):\n",
    "                review_str = review_str + j +' '\n",
    "        \n",
    "        #print(model(review_str).vector.shape)\n",
    "        #print(reviewer_vectors.shape)\n",
    "            reviewer_vectors[i] = model(review_str).vector\n",
    "    \n",
    "    return reviewer_vectors\n",
    "\n",
    "def GetCosineSims(doc_vec, review_vec, df_reviewers=df_reviewers):\n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_cosine_sims = []\n",
    "    for j in range(len(review_vec)):\n",
    "        if pd.isna(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing']) == False:\n",
    "            all_cosine_sims.append(cosine_similarity(np.array([doc_vec]), np.array([review_vec[j]]))[0,0])\n",
    "            all_domains.append(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing'].lower())\n",
    "            all_usernames.append(df_reviewers.iloc[j+1].username)\n",
    "    all_usernames= np.array(all_usernames)\n",
    "    all_domains= np.array(all_domains)\n",
    "    all_cosine_sims= np.array(all_cosine_sims)\n",
    "    \n",
    "    return all_usernames, all_domains, all_cosine_sims\n",
    "\n",
    "def Get_Paper_Vector_Idea6_SpaCy(arr,model):\n",
    "    sum_vector_text = np.zeros((300))\n",
    "    count = 0\n",
    "    for J in range(len(arr)):\n",
    "        sum_line_vector_text = model(str(arr[J])).vector\n",
    "        counter = len(arr[J].split())\n",
    "        \n",
    "        average_line_vector_text = sum_line_vector_text/ counter\n",
    "        sum_vector_text = sum_vector_text + average_line_vector_text\n",
    "        count = count + 1\n",
    "        \n",
    "    average_vector_text = sum_vector_text / count\n",
    "    return average_vector_text\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 3 TF spaCy ####################\n",
    "    \n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 3 TF-IDF spaCy ####################\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 4 spaCy ####################\n",
    "\n",
    "# No Functions\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 6 spaCy ####################\n",
    "\n",
    "\n",
    "    \n",
    "def Idea6_lemma_Text(arr):\n",
    "    text_list = []\n",
    "    for J in range(len(arr)):\n",
    "        doc = model(str(arr[J]))\n",
    "        \n",
    "        doc_arr = []\n",
    "        for token in doc:\n",
    "            if token.is_alpha == True:\n",
    "                if token.is_stop == False:\n",
    "                    doc_arr.append(str(token.lemma_).lower())\n",
    "        doc_arr = np.array(doc_arr)\n",
    "        \n",
    "        doc_arr_mod = ''\n",
    "        for i in doc_arr:\n",
    "            doc_arr_mod = doc_arr_mod + i +' '\n",
    "        #print(doc_arr_mod)\n",
    "        text_list.append(doc_arr_mod)\n",
    "    return text_list\n",
    "\n",
    "def Idea6_unique_lemma_Text(arr):\n",
    "    text_list = []\n",
    "    for J in range(len(arr)):\n",
    "        doc = model(str(arr[J]))\n",
    "        \n",
    "        doc_arr = []\n",
    "        for token in doc:\n",
    "            if token.is_alpha == True:\n",
    "                if token.is_stop == False:\n",
    "                    doc_arr.append(str(token.lemma_).lower())\n",
    "        doc_arr = np.array(doc_arr)\n",
    "        doc_str = ''\n",
    "        for i in np.unique(doc_arr):\n",
    "            doc_str = doc_str + i +' '\n",
    "        text_list.append(doc_str)\n",
    "    return text_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#########################################################################################################################################################\n",
    "\n",
    "################# Idea 9 Sense2Vec ####################\n",
    "\n",
    "\n",
    "def GetPaperVector_Sense2Vec(text):\n",
    "    doc = model(text)\n",
    "    doc_arr = []\n",
    "    pos_arr = []\n",
    "    tag_arr = []\n",
    "    dep_arr = []\n",
    "    for token in doc:\n",
    "        if token.is_alpha == True:\n",
    "            if token.is_stop == False:\n",
    "                doc_arr.append(str(token.lemma_).lower())\n",
    "                pos_arr.append(str(token.pos_))\n",
    "                tag_arr.append(str(token.tag_))\n",
    "                dep_arr.append(str(token.dep_))\n",
    "            \n",
    "    doc_arr = np.array(doc_arr)\n",
    "    pos_arr = np.array(pos_arr)\n",
    "    tag_arr = np.array(tag_arr)\n",
    "    dep_arr = np.array(dep_arr)\n",
    "\n",
    "    word_vec = np.zeros((128))\n",
    "    counter = 0\n",
    "    for P in range(len(doc_arr)):\n",
    "        best = s2v.get_best_sense(doc_arr[P])\n",
    "        if best != None:\n",
    "            vector = s2v[best]\n",
    "            word_vec = word_vec + vector\n",
    "            counter = counter + 1\n",
    "    average_word_vec = word_vec / counter\n",
    "    \n",
    "    return average_word_vec\n",
    "\n",
    "\n",
    "\n",
    "def GetReviewerSample_Sense2Vec(paper_vec, df_reviewers=df_reviewers):\n",
    "    all_usernames = []\n",
    "    all_domains = []\n",
    "    all_cosine_sims = []\n",
    "    for j in range(df_reviewers.shape[0]-1):\n",
    "        if pd.isna(df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing']) == False:\n",
    "            reviewer_interests = df_reviewers.iloc[j+1]['Domains/topic areas you are comfortable reviewing'].lower()\n",
    "            reviewer_interests.replace('/',' ')\n",
    "            doc = model(reviewer_interests)\n",
    "            reviewer_arr = []\n",
    "            for token in doc:\n",
    "                if token.is_alpha == True:\n",
    "                    if token.is_stop == False:\n",
    "                        reviewer_arr.append(str(token.lemma_).lower())\n",
    "            reviewer_arr = np.array(reviewer_arr)\n",
    "            word_vec = np.zeros((128))\n",
    "            counter = 0\n",
    "            for P in range(len(reviewer_arr)):\n",
    "                best = s2v.get_best_sense(reviewer_arr[P])\n",
    "                if best != None:\n",
    "                    vector = s2v[best]\n",
    "                    word_vec = word_vec + vector\n",
    "                    counter = counter + 1\n",
    "            \n",
    "            if counter > 0:\n",
    "                average_reviewer_vec = word_vec / counter\n",
    "          \n",
    "                all_usernames.append(df_reviewers.username.iloc[j+1])\n",
    "                all_domains.append(reviewer_interests)\n",
    "                all_cosine_sims.append(cosine_similarity(np.array([paper_vec]), np.array([average_reviewer_vec]))[0,0])\n",
    "    return np.array(all_usernames), np.array(all_domains), np.array(all_cosine_sims)\n",
    " \n",
    "def TopReviewers(number, all_usernames, all_domains, all_cosine_sims):\n",
    "    message = 'Hello.\\nI have found ' +str(number) + ' possible reviewers for this paper.'+ '\\n\\n'\n",
    "    for J in range(number):\n",
    "        index = np.argsort(all_cosine_sims)[-1-J]\n",
    "        #print(index)\n",
    "        ps = 'I believe '+ colored(str(all_usernames[index]), 'green') + ' will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of ' + colored(str(all_cosine_sims[index])[:6], 'blue') + '. This reviewers domain interests are ' + colored(str(all_domains[index].replace('\\n', ',')), 'red')\n",
    "        message = message + ps + '\\n\\n'\n",
    "    print(message) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4c0fe-d5c1-4f79-afd5-d91f3a0c1d73",
   "metadata": {},
   "source": [
    "# Idea 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1c9b134-8138-4cf4-b03b-b73b1ddf1417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_usernames_Idea_1, all_domains_Idea_1, all_num_matched_words_Idea_1, all_matched_words_Idea_1 = Get_reviewer_sample_tf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "486e292b-477f-47d5-aad0-f0ea84388a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. \n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32mAdrianzo\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m2\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['calling', 'variant']\u001b[0m.\n",
      "From their topics domain: \u001b[31mvariant calling, complex diseases, rare variants, epigenetics\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mhtwangtw\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m2\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['file', 'format']\u001b[0m.\n",
      "From their topics domain: \u001b[31mneuroimaging, data workflow, file format\u001b[0m.\n",
      "\n",
      "I believe \u001b[32marunmano121\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m2\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['python', 'software']\u001b[0m.\n",
      "From their topics domain: \u001b[31mvisualization,  software,  python,  bash,  nondestructive testing,  structural health monitoring\u001b[0m.\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m2\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['python', 'software']\u001b[0m.\n",
      "From their topics domain: \u001b[31mpython,  distributed computing,  real time processing,  image processing,  graphs & graph databases,  nosql databases,  algorithms,  software development methodologies\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mgsfyrakis\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m1\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['software']\u001b[0m.\n",
      "From their topics domain: \u001b[31msecurity, blockchain, distributed system, trusted software\u001b[0m.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summatation_bot_tf(all_usernames_Idea_1, all_domains_Idea_1, all_num_matched_words_Idea_1, all_matched_words_Idea_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a48ce4-2ffb-4483-91ed-3572b06a182d",
   "metadata": {},
   "source": [
    "# Idea 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2802726-c921-4979-a667-0abc6ad24a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_usernames_Idea_2, all_domains_Idea_2, all_num_matched_words_Idea_2, all_matched_words_Idea_2 = Get_reviewer_sample_tf_idf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8e45fc8f-bf32-499d-8e21-d01fd91289a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. \n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32mscivision\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m2\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['benchmarking', 'file']\u001b[0m.\n",
      "From their topics domain: \u001b[31mbuild systems, file i/o, benchmarking, multi-code language interfaces\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mtacaswell\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m1\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['python']\u001b[0m.\n",
      "From their topics domain: \u001b[31mplotting in python, soft matter physics, xray science\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mlankasaicharan\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m1\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['python']\u001b[0m.\n",
      "From their topics domain: \u001b[31mvlsi cad, python applications, docker applications\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mzbeekman\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m1\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['package']\u001b[0m.\n",
      "From their topics domain: \u001b[31mcomputational fluid dynamics (cfd),  fortran tools, utilities, libraries, solvers, programs,  ci/cd & devops for computational science and engineering,  hpc applications, frameworks, & tools,  numerical solution of pdes,  performance analysis & performance engineering tools,  multi-physics frameworks & applications,  legacy application refactoring tools,  parallel & pgas runtimes/rtls,  package managers,  macos tools & utilities\u001b[0m.\n",
      "\n",
      "I believe \u001b[32mdruvus\u001b[0m will make a good reviewer for this paper because they have matched \u001b[34m1\u001b[0m words from their comfortable domain topics with the top 20 most frequent words in the paper. These matched words are \u001b[34m['sequencing']\u001b[0m.\n",
      "From their topics domain: \u001b[31msequencing,  genomics,  transcriptomics,  metagenomics\u001b[0m.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summatation_bot_tf_idf(all_usernames_Idea_2, all_domains_Idea_2, all_num_matched_words_Idea_2, all_matched_words_Idea_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc22cc9-071e-4ac5-88c0-90af99c902f9",
   "metadata": {},
   "source": [
    "# Following code is separated by Python package used rather than Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2878ef-1b88-44be-a5b3-1c0933f021f1",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4459753e-e42a-4fc9-b5b9-fd0dc1dec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Volumes/Seagate Backup Plus Drive/JOSS Project/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8614627-0664-4fdb-bd70-6365faed452b",
   "metadata": {},
   "source": [
    "# Idea 3 TF (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c86d1f06-1cc2-4202-9df1-d6f5f10eb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tf = Get_Top_Words_tf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "876748a5-28fc-4118-a4c6-fd70f8f3766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['variant', 'vcf', 'file', 'package', 'comparing', 'call', 'format',\n",
       "       'et', 'vcftoolz', 'calling', 'compare', 'algorithm', 'software',\n",
       "       'capability', 'python', 'evaluating', 'multiple', 'november',\n",
       "       'work', 'food'], dtype='<U21')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9289e3f7-b0c6-4bba-8aad-31c1c9b26f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcf\n",
      "vcftoolz\n"
     ]
    }
   ],
   "source": [
    "average_vector_text = W2V_Gensim_Processing_tf(top20_tf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "476e9e80-9f0d-49d5-8d41-d5bec58be8bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcmc\n",
      "visualisation\n",
      "giscience\n",
      "archaeology\n",
      "openmp\n",
      "modelling\n",
      "modelling\n",
      "euroimaging\n",
      "visualisation\n",
      "visualisation\n",
      "frequentist\n",
      "django\n",
      "microservices\n",
      "pde\n",
      "schrodinger\n",
      "knl\n",
      "sowftware\n",
      "characterisation\n",
      "nanophysics\n",
      "viszalization\n",
      "munging\n",
      "biotatistics\n",
      "fmri\n",
      "blockchain\n",
      "postestimation\n",
      "modelling\n",
      "nlp\n",
      "modelling\n",
      "sciencies\n",
      "bibliometry\n",
      "scientometry\n",
      "giscience\n",
      "munging\n",
      "datavis\n",
      "minirg\n",
      "biostats\n",
      "biofinromatics\n",
      "markov\n",
      "modelling\n",
      "biostats\n",
      "nlp\n",
      "modelling\n",
      "pcr\n",
      "chemistryphysical\n",
      "cryptocurrency\n",
      "bdi\n",
      "provers\n",
      "healthit\n",
      "behaviour\n",
      "visualisation\n",
      "astrostatistics\n",
      "analyses\n",
      "nosql\n",
      "modelling\n",
      "visualisation\n",
      "htmlwidgets\n",
      "keras\n",
      "reducation\n",
      "wcet\n",
      "analyses\n",
      "meshless\n",
      "meshfree\n",
      "bioimage\n",
      "visualisation\n",
      "optimisation\n",
      "nlp\n",
      "devsecops\n",
      "visualisation\n",
      "devops\n",
      "nlp\n",
      "sicence\n",
      "mrio\n",
      "lca\n",
      "dsmc\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "visualisation\n",
      "analyses\n",
      "astrodynamics\n",
      "langevin\n",
      "jupyter\n",
      "pde\n",
      "modelling\n",
      "openmp\n",
      "markov\n",
      "archaeology\n",
      "fortran\n",
      "devops\n",
      "pdes\n",
      "pgas\n",
      "macos\n",
      "modelling\n",
      "optimisation\n",
      "algorithmics\n",
      "metabarcoding\n",
      "behavioural\n",
      "astrodynamics\n",
      "ipywidgets\n",
      "visualisation\n",
      "insar\n",
      "mle\n",
      "asdasd\n",
      "sequecning\n",
      "munging\n",
      "gamess\n",
      "delaunay\n",
      "voronoi\n",
      "modelling\n",
      "nlp\n",
      "nlp\n",
      "modelling\n",
      "geocomputation\n",
      "geosimulations\n",
      "astroparticle\n",
      "optimisation\n",
      "modelling\n",
      "scientometrics\n",
      "informetrics\n",
      "pointclouds\n",
      "mapreduce\n",
      "visualisation\n",
      "mcmc\n",
      "visualisation\n",
      "gpus\n",
      "bioinspired\n",
      "nlp\n",
      "kubernetes\n",
      "nlp\n",
      "rstats\n",
      "astroparticle\n",
      "modelling\n",
      "nbody\n",
      "cmb\n",
      "optimisation\n",
      "organisation\n",
      "modelling\n",
      "wikimedia\n",
      "mediawiki\n",
      "astrodynamics\n",
      "modelling\n",
      "fmri\n",
      "modelling\n",
      "magnetohydrodynamics\n",
      "colour\n",
      "modelling\n",
      "fluiddynamics\n",
      "modelling\n",
      "eeg\n",
      "visualisation\n",
      "modelling\n",
      "geomorph\n",
      "visualisation\n",
      "fmri\n",
      "eeg\n",
      "pupillometry\n",
      "nlp\n",
      "netowork\n",
      "goesciences\n",
      "labstraming\n",
      "lca\n",
      "visualisation\n",
      "modelling\n",
      "pdes\n",
      "melnikov\n",
      "pdes\n",
      "characterisation\n",
      "ebsd\n",
      "modelling\n",
      "convolutional\n",
      "visualisation\n",
      "tidyverse\n",
      "aeroelasticity\n",
      "optimisation\n",
      "dfghgtf\n",
      "sotware\n",
      "optimisation\n",
      "geospational\n",
      "phylogeography\n",
      "openfoam\n",
      "modelling\n",
      "nlp\n",
      "dicom\n",
      "fhir\n",
      "devops\n",
      "nlp\n",
      "estatistical\n",
      "visualisation\n",
      "modelling\n",
      "brojournal\n",
      "diffing\n",
      "bindiffing\n",
      "isomorphism\n",
      "behaviour\n",
      "rnaseq\n",
      "munging\n",
      "mklr\n",
      "modelling\n",
      "abm\n",
      "modelling\n",
      "mcmc\n",
      "mcmc\n",
      "newtonian\n",
      "nilm\n",
      "deeplearning\n",
      "segmantation\n",
      "pdes\n",
      "eeg\n",
      "ieeg\n",
      "nlp\n",
      "dataviz\n",
      "snv\n",
      "humour\n",
      "multigrid\n",
      "satisfiability\n",
      "visualisation\n",
      "archaeology\n",
      "archaeology\n",
      "visualisation\n",
      "munging\n",
      "blockchain\n",
      "modelling\n",
      "modelling\n",
      "humanties\n",
      "pupillometry\n",
      "fmm\n",
      "visualisation\n",
      "visualisation\n",
      "mcmc\n",
      "nlp\n",
      "markov\n",
      "pyrometallurgy\n",
      "thermochemistry\n",
      "visualisation\n",
      "cdisc\n",
      "modelling\n",
      "informetrics\n",
      "modelling\n",
      "milps\n",
      "mmilps\n",
      "gwas\n",
      "jupyter\n",
      "modelling\n",
      "modelling\n",
      "behavioural\n",
      "organisational\n",
      "eeg\n",
      "modelling\n",
      "abms\n",
      "nlp\n",
      "magnetohydrodynamics\n",
      "behaviour\n",
      "qcd\n",
      "boltzmann\n",
      "sience\n",
      "qma\n",
      "optimisation\n",
      "biosignals\n",
      "bioimage\n",
      "visualisation\n",
      "eigenvectors\n",
      "pdes\n",
      "modelling\n",
      "rna\n",
      "modelling\n",
      "modelling\n",
      "bioimage\n",
      "hypergeometric\n",
      "eeg\n",
      "qgis\n",
      "optimisation\n",
      "markov\n",
      "snvs\n",
      "blockchain\n",
      "phylodynamics\n",
      "analyse\n",
      "uas\n",
      "tidyverse\n",
      "visualisation\n",
      "tidyverse\n",
      "cmake\n",
      "astroparticle\n",
      "eeg\n",
      "fmri\n",
      "modelling\n",
      "datastructure\n",
      "fmri\n",
      "eeg\n",
      "eeg\n",
      "astrodynamics\n",
      "mcmc\n",
      "archaeology\n",
      "openbim\n",
      "simd\n",
      "gpgpu\n",
      "modelling\n",
      "visualisation\n",
      "pde\n",
      "linguistis\n",
      "dialectology\n",
      "modelling\n",
      "characterisation\n",
      "bibliometrix\n",
      "adverserial\n",
      "modelling\n",
      "multimodel\n",
      "tensorflow\n",
      "optimisation\n",
      "modelling\n",
      "fmri\n",
      "behavioural\n",
      "modelling\n",
      "fmri\n",
      "clinica\n",
      "neurocience\n",
      "nextflow\n",
      "tidyverse\n",
      "rlang\n",
      "mysore\n",
      "funcional\n",
      "sdr\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "networkx\n",
      "astroparticle\n",
      "eeg\n",
      "nmr\n",
      "fhir\n",
      "nlp\n",
      "gggg\n",
      "devops\n",
      "rna\n",
      "vlsi\n",
      "behaviour\n",
      "cosmochemistry\n",
      "practises\n",
      "pdes\n",
      "galerkin\n",
      "wfe\n",
      "nlp\n",
      "fortran\n",
      "ansible\n",
      "archaeology\n",
      "hohai\n",
      "geocomputation\n",
      "uitilities\n",
      "flamegraphs\n",
      "modelling\n",
      "sedimentolgoical\n",
      "ndt\n",
      "metaheuristics\n",
      "mqtt\n",
      "dnssec\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "nlp\n",
      "astrodynamics\n",
      "modelling\n",
      "modelling\n",
      "mecânica\n",
      "termodinâmica\n",
      "uml\n",
      "signalling\n",
      "rnaseq\n",
      "multiomics\n",
      "astroparticle\n",
      "modelling\n",
      "modelling\n",
      "infrostructure\n",
      "parametrization\n",
      "qgis\n",
      "fmri\n",
      "sdr\n",
      "modelling\n",
      "analyses\n",
      "nlp\n",
      "distributionally\n",
      "archaeology\n",
      "kalman\n"
     ]
    }
   ],
   "source": [
    "all_usernames_W2V_Gensim_Idea_3_TF, all_domains_W2V_Gensim_Idea_3_TF, all_cosine_sims_W2V_Gensim_Idea_3_TF = GetReviewerSample_W2V_Gensim(average_vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27d7f4a0-4603-4be4-8d74-0c66778036c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6557\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mLogIN-\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6445\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, biology, big data, web based software, api design\u001b[0m\n",
      "\n",
      "I believe \u001b[32mscivision\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6356\u001b[0m. This reviewers domain interests are \u001b[31mbuild systems, file i/o, benchmarking, multi-code language interfaces\u001b[0m\n",
      "\n",
      "I believe \u001b[32mShathra\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6337\u001b[0m. This reviewers domain interests are \u001b[31mmatrix factorization, parallel computing, machine learning, ai, graph algorithms\u001b[0m\n",
      "\n",
      "I believe \u001b[32malexpghayes\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6333\u001b[0m. This reviewers domain interests are \u001b[31mi'm interested in making sure that r packages for modelling have useful and intuitive interfaces and documentation. i'm not interested in double checking theory and correctness, but making sure that a new user can quickly and easily get the results they want.\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers_W2V_Gensim(5,all_usernames_W2V_Gensim_Idea_3_TF, all_domains_W2V_Gensim_Idea_3_TF, all_cosine_sims_W2V_Gensim_Idea_3_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc2128-03bf-4c3c-8163-11af6e4c9e1e",
   "metadata": {},
   "source": [
    "# Idea 3 TF-IDF (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a1db242-574c-473f-b797-f0542e772e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tf_idf = Get_Top_Words_tf_idf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a2369c0-f523-4ca7-a07e-2df877d63ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vcf', 'rtg', 'venn', 'benchmarking', 'concordance', 'spreadsheet',\n",
       "       'python', 'snp', 'evaluating', 'algorithm', 'variant', 'caller',\n",
       "       'comparing', 'compare', 'sequencing', 'file', 'artifact',\n",
       "       'package', 'capability', 'facilitates'], dtype='<U13')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66d1b1ae-e7f0-48f2-9b6b-377d62fbea70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcf\n",
      "venn\n",
      "snp\n"
     ]
    }
   ],
   "source": [
    "average_vector_text = W2V_Gensim_Processing_tf(top20_tf_idf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cf9f571-8d94-40ac-86de-63d8809ad7f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcmc\n",
      "visualisation\n",
      "giscience\n",
      "archaeology\n",
      "openmp\n",
      "modelling\n",
      "modelling\n",
      "euroimaging\n",
      "visualisation\n",
      "visualisation\n",
      "frequentist\n",
      "django\n",
      "microservices\n",
      "pde\n",
      "schrodinger\n",
      "knl\n",
      "sowftware\n",
      "characterisation\n",
      "nanophysics\n",
      "viszalization\n",
      "munging\n",
      "biotatistics\n",
      "fmri\n",
      "blockchain\n",
      "postestimation\n",
      "modelling\n",
      "nlp\n",
      "modelling\n",
      "sciencies\n",
      "bibliometry\n",
      "scientometry\n",
      "giscience\n",
      "munging\n",
      "datavis\n",
      "minirg\n",
      "biostats\n",
      "biofinromatics\n",
      "markov\n",
      "modelling\n",
      "biostats\n",
      "nlp\n",
      "modelling\n",
      "pcr\n",
      "chemistryphysical\n",
      "cryptocurrency\n",
      "bdi\n",
      "provers\n",
      "healthit\n",
      "behaviour\n",
      "visualisation\n",
      "astrostatistics\n",
      "analyses\n",
      "nosql\n",
      "modelling\n",
      "visualisation\n",
      "htmlwidgets\n",
      "keras\n",
      "reducation\n",
      "wcet\n",
      "analyses\n",
      "meshless\n",
      "meshfree\n",
      "bioimage\n",
      "visualisation\n",
      "optimisation\n",
      "nlp\n",
      "devsecops\n",
      "visualisation\n",
      "devops\n",
      "nlp\n",
      "sicence\n",
      "mrio\n",
      "lca\n",
      "dsmc\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "visualisation\n",
      "analyses\n",
      "astrodynamics\n",
      "langevin\n",
      "jupyter\n",
      "pde\n",
      "modelling\n",
      "openmp\n",
      "markov\n",
      "archaeology\n",
      "fortran\n",
      "devops\n",
      "pdes\n",
      "pgas\n",
      "macos\n",
      "modelling\n",
      "optimisation\n",
      "algorithmics\n",
      "metabarcoding\n",
      "behavioural\n",
      "astrodynamics\n",
      "ipywidgets\n",
      "visualisation\n",
      "insar\n",
      "mle\n",
      "asdasd\n",
      "sequecning\n",
      "munging\n",
      "gamess\n",
      "delaunay\n",
      "voronoi\n",
      "modelling\n",
      "nlp\n",
      "nlp\n",
      "modelling\n",
      "geocomputation\n",
      "geosimulations\n",
      "astroparticle\n",
      "optimisation\n",
      "modelling\n",
      "scientometrics\n",
      "informetrics\n",
      "pointclouds\n",
      "mapreduce\n",
      "visualisation\n",
      "mcmc\n",
      "visualisation\n",
      "gpus\n",
      "bioinspired\n",
      "nlp\n",
      "kubernetes\n",
      "nlp\n",
      "rstats\n",
      "astroparticle\n",
      "modelling\n",
      "nbody\n",
      "cmb\n",
      "optimisation\n",
      "organisation\n",
      "modelling\n",
      "wikimedia\n",
      "mediawiki\n",
      "astrodynamics\n",
      "modelling\n",
      "fmri\n",
      "modelling\n",
      "magnetohydrodynamics\n",
      "colour\n",
      "modelling\n",
      "fluiddynamics\n",
      "modelling\n",
      "eeg\n",
      "visualisation\n",
      "modelling\n",
      "geomorph\n",
      "visualisation\n",
      "fmri\n",
      "eeg\n",
      "pupillometry\n",
      "nlp\n",
      "netowork\n",
      "goesciences\n",
      "labstraming\n",
      "lca\n",
      "visualisation\n",
      "modelling\n",
      "pdes\n",
      "melnikov\n",
      "pdes\n",
      "characterisation\n",
      "ebsd\n",
      "modelling\n",
      "convolutional\n",
      "visualisation\n",
      "tidyverse\n",
      "aeroelasticity\n",
      "optimisation\n",
      "dfghgtf\n",
      "sotware\n",
      "optimisation\n",
      "geospational\n",
      "phylogeography\n",
      "openfoam\n",
      "modelling\n",
      "nlp\n",
      "dicom\n",
      "fhir\n",
      "devops\n",
      "nlp\n",
      "estatistical\n",
      "visualisation\n",
      "modelling\n",
      "brojournal\n",
      "diffing\n",
      "bindiffing\n",
      "isomorphism\n",
      "behaviour\n",
      "rnaseq\n",
      "munging\n",
      "mklr\n",
      "modelling\n",
      "abm\n",
      "modelling\n",
      "mcmc\n",
      "mcmc\n",
      "newtonian\n",
      "nilm\n",
      "deeplearning\n",
      "segmantation\n",
      "pdes\n",
      "eeg\n",
      "ieeg\n",
      "nlp\n",
      "dataviz\n",
      "snv\n",
      "humour\n",
      "multigrid\n",
      "satisfiability\n",
      "visualisation\n",
      "archaeology\n",
      "archaeology\n",
      "visualisation\n",
      "munging\n",
      "blockchain\n",
      "modelling\n",
      "modelling\n",
      "humanties\n",
      "pupillometry\n",
      "fmm\n",
      "visualisation\n",
      "visualisation\n",
      "mcmc\n",
      "nlp\n",
      "markov\n",
      "pyrometallurgy\n",
      "thermochemistry\n",
      "visualisation\n",
      "cdisc\n",
      "modelling\n",
      "informetrics\n",
      "modelling\n",
      "milps\n",
      "mmilps\n",
      "gwas\n",
      "jupyter\n",
      "modelling\n",
      "modelling\n",
      "behavioural\n",
      "organisational\n",
      "eeg\n",
      "modelling\n",
      "abms\n",
      "nlp\n",
      "magnetohydrodynamics\n",
      "behaviour\n",
      "qcd\n",
      "boltzmann\n",
      "sience\n",
      "qma\n",
      "optimisation\n",
      "biosignals\n",
      "bioimage\n",
      "visualisation\n",
      "eigenvectors\n",
      "pdes\n",
      "modelling\n",
      "rna\n",
      "modelling\n",
      "modelling\n",
      "bioimage\n",
      "hypergeometric\n",
      "eeg\n",
      "qgis\n",
      "optimisation\n",
      "markov\n",
      "snvs\n",
      "blockchain\n",
      "phylodynamics\n",
      "analyse\n",
      "uas\n",
      "tidyverse\n",
      "visualisation\n",
      "tidyverse\n",
      "cmake\n",
      "astroparticle\n",
      "eeg\n",
      "fmri\n",
      "modelling\n",
      "datastructure\n",
      "fmri\n",
      "eeg\n",
      "eeg\n",
      "astrodynamics\n",
      "mcmc\n",
      "archaeology\n",
      "openbim\n",
      "simd\n",
      "gpgpu\n",
      "modelling\n",
      "visualisation\n",
      "pde\n",
      "linguistis\n",
      "dialectology\n",
      "modelling\n",
      "characterisation\n",
      "bibliometrix\n",
      "adverserial\n",
      "modelling\n",
      "multimodel\n",
      "tensorflow\n",
      "optimisation\n",
      "modelling\n",
      "fmri\n",
      "behavioural\n",
      "modelling\n",
      "fmri\n",
      "clinica\n",
      "neurocience\n",
      "nextflow\n",
      "tidyverse\n",
      "rlang\n",
      "mysore\n",
      "funcional\n",
      "sdr\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "networkx\n",
      "astroparticle\n",
      "eeg\n",
      "nmr\n",
      "fhir\n",
      "nlp\n",
      "gggg\n",
      "devops\n",
      "rna\n",
      "vlsi\n",
      "behaviour\n",
      "cosmochemistry\n",
      "practises\n",
      "pdes\n",
      "galerkin\n",
      "wfe\n",
      "nlp\n",
      "fortran\n",
      "ansible\n",
      "archaeology\n",
      "hohai\n",
      "geocomputation\n",
      "uitilities\n",
      "flamegraphs\n",
      "modelling\n",
      "sedimentolgoical\n",
      "ndt\n",
      "metaheuristics\n",
      "mqtt\n",
      "dnssec\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "nlp\n",
      "astrodynamics\n",
      "modelling\n",
      "modelling\n",
      "mecânica\n",
      "termodinâmica\n",
      "uml\n",
      "signalling\n",
      "rnaseq\n",
      "multiomics\n",
      "astroparticle\n",
      "modelling\n",
      "modelling\n",
      "infrostructure\n",
      "parametrization\n",
      "qgis\n",
      "fmri\n",
      "sdr\n",
      "modelling\n",
      "analyses\n",
      "nlp\n",
      "distributionally\n",
      "archaeology\n",
      "kalman\n"
     ]
    }
   ],
   "source": [
    "all_usernames_W2V_Gensim_Idea_3_TF_IDF, all_domains_W2V_Gensim_Idea_3_TF_IDF, all_cosine_sims_W2V_Gensim_Idea_3_TF_IDF = GetReviewerSample_W2V_Gensim(average_vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "07a2fd4e-73d4-4dd8-a3a3-fd2f9b3061ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6932\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mcorybrunson\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6825\u001b[0m. This reviewers domain interests are \u001b[31mpackages, data visualization, geometry, topology, combinatorics, graph theory, geometric, network, and topological data analysis, statistical modeling, bibliometry, scientometry, [glad to consider anything and will reply quickly if not qualified]\u001b[0m\n",
      "\n",
      "I believe \u001b[32msauln\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6779\u001b[0m. This reviewers domain interests are \u001b[31mtopological data analysis, machine learning, user interfaces\u001b[0m\n",
      "\n",
      "I believe \u001b[32mprasantapal\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6674\u001b[0m. This reviewers domain interests are \u001b[31malgorithms, statistical analysis, image processing, data science, realtime system\u001b[0m\n",
      "\n",
      "I believe \u001b[32marunmano121\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.6641\u001b[0m. This reviewers domain interests are \u001b[31mdata analytics, artificial intelligence, big data, statistical modeling, analytics, regression, machine learning, deep learning, neural networks, gradient boosting, nondestructive testing, structural health monitoring, python\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers_W2V_Gensim(5,all_usernames_W2V_Gensim_Idea_3_TF_IDF, all_domains_W2V_Gensim_Idea_3_TF_IDF, all_cosine_sims_W2V_Gensim_Idea_3_TF_IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311f16a-03ad-418c-af32-35686db39605",
   "metadata": {},
   "source": [
    "# Idea 4 (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27215f25-84f6-4e9d-ba6d-e89e1d43978a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcftoolz\n",
      "vcf\n",
      "vcf\n",
      "vcf\n",
      "vcftoolz\n",
      "vcf\n",
      "snps\n",
      "vcftoolz\n",
      "vcf\n",
      "vcftoolz\n",
      "vcf\n",
      "pypi\n"
     ]
    }
   ],
   "source": [
    "texts, arr = MakeGreenRedText(Paper_interest,False)\n",
    "average_vector_text = W2V_Gensim_Processing(texts, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d7b4b0a4-9fa7-420e-a02e-a880280101ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcmc\n",
      "visualisation\n",
      "giscience\n",
      "archaeology\n",
      "openmp\n",
      "modelling\n",
      "modelling\n",
      "euroimaging\n",
      "visualisation\n",
      "visualisation\n",
      "frequentist\n",
      "django\n",
      "microservices\n",
      "pde\n",
      "schrodinger\n",
      "knl\n",
      "sowftware\n",
      "characterisation\n",
      "nanophysics\n",
      "viszalization\n",
      "munging\n",
      "biotatistics\n",
      "fmri\n",
      "blockchain\n",
      "postestimation\n",
      "modelling\n",
      "nlp\n",
      "modelling\n",
      "sciencies\n",
      "bibliometry\n",
      "scientometry\n",
      "giscience\n",
      "munging\n",
      "datavis\n",
      "minirg\n",
      "biostats\n",
      "biofinromatics\n",
      "markov\n",
      "modelling\n",
      "biostats\n",
      "nlp\n",
      "modelling\n",
      "pcr\n",
      "chemistryphysical\n",
      "cryptocurrency\n",
      "bdi\n",
      "provers\n",
      "healthit\n",
      "behaviour\n",
      "visualisation\n",
      "astrostatistics\n",
      "analyses\n",
      "nosql\n",
      "modelling\n",
      "visualisation\n",
      "htmlwidgets\n",
      "keras\n",
      "reducation\n",
      "wcet\n",
      "analyses\n",
      "meshless\n",
      "meshfree\n",
      "bioimage\n",
      "visualisation\n",
      "optimisation\n",
      "nlp\n",
      "devsecops\n",
      "visualisation\n",
      "devops\n",
      "nlp\n",
      "sicence\n",
      "mrio\n",
      "lca\n",
      "dsmc\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "visualisation\n",
      "analyses\n",
      "astrodynamics\n",
      "langevin\n",
      "jupyter\n",
      "pde\n",
      "modelling\n",
      "openmp\n",
      "markov\n",
      "archaeology\n",
      "fortran\n",
      "devops\n",
      "pdes\n",
      "pgas\n",
      "macos\n",
      "modelling\n",
      "optimisation\n",
      "algorithmics\n",
      "metabarcoding\n",
      "behavioural\n",
      "astrodynamics\n",
      "ipywidgets\n",
      "visualisation\n",
      "insar\n",
      "mle\n",
      "asdasd\n",
      "sequecning\n",
      "munging\n",
      "gamess\n",
      "delaunay\n",
      "voronoi\n",
      "modelling\n",
      "nlp\n",
      "nlp\n",
      "modelling\n",
      "geocomputation\n",
      "geosimulations\n",
      "astroparticle\n",
      "optimisation\n",
      "modelling\n",
      "scientometrics\n",
      "informetrics\n",
      "pointclouds\n",
      "mapreduce\n",
      "visualisation\n",
      "mcmc\n",
      "visualisation\n",
      "gpus\n",
      "bioinspired\n",
      "nlp\n",
      "kubernetes\n",
      "nlp\n",
      "rstats\n",
      "astroparticle\n",
      "modelling\n",
      "nbody\n",
      "cmb\n",
      "optimisation\n",
      "organisation\n",
      "modelling\n",
      "wikimedia\n",
      "mediawiki\n",
      "astrodynamics\n",
      "modelling\n",
      "fmri\n",
      "modelling\n",
      "magnetohydrodynamics\n",
      "colour\n",
      "modelling\n",
      "fluiddynamics\n",
      "modelling\n",
      "eeg\n",
      "visualisation\n",
      "modelling\n",
      "geomorph\n",
      "visualisation\n",
      "fmri\n",
      "eeg\n",
      "pupillometry\n",
      "nlp\n",
      "netowork\n",
      "goesciences\n",
      "labstraming\n",
      "lca\n",
      "visualisation\n",
      "modelling\n",
      "pdes\n",
      "melnikov\n",
      "pdes\n",
      "characterisation\n",
      "ebsd\n",
      "modelling\n",
      "convolutional\n",
      "visualisation\n",
      "tidyverse\n",
      "aeroelasticity\n",
      "optimisation\n",
      "dfghgtf\n",
      "sotware\n",
      "optimisation\n",
      "geospational\n",
      "phylogeography\n",
      "openfoam\n",
      "modelling\n",
      "nlp\n",
      "dicom\n",
      "fhir\n",
      "devops\n",
      "nlp\n",
      "estatistical\n",
      "visualisation\n",
      "modelling\n",
      "brojournal\n",
      "diffing\n",
      "bindiffing\n",
      "isomorphism\n",
      "behaviour\n",
      "rnaseq\n",
      "munging\n",
      "mklr\n",
      "modelling\n",
      "abm\n",
      "modelling\n",
      "mcmc\n",
      "mcmc\n",
      "newtonian\n",
      "nilm\n",
      "deeplearning\n",
      "segmantation\n",
      "pdes\n",
      "eeg\n",
      "ieeg\n",
      "nlp\n",
      "dataviz\n",
      "snv\n",
      "humour\n",
      "multigrid\n",
      "satisfiability\n",
      "visualisation\n",
      "archaeology\n",
      "archaeology\n",
      "visualisation\n",
      "munging\n",
      "blockchain\n",
      "modelling\n",
      "modelling\n",
      "humanties\n",
      "pupillometry\n",
      "fmm\n",
      "visualisation\n",
      "visualisation\n",
      "mcmc\n",
      "nlp\n",
      "markov\n",
      "pyrometallurgy\n",
      "thermochemistry\n",
      "visualisation\n",
      "cdisc\n",
      "modelling\n",
      "informetrics\n",
      "modelling\n",
      "milps\n",
      "mmilps\n",
      "gwas\n",
      "jupyter\n",
      "modelling\n",
      "modelling\n",
      "behavioural\n",
      "organisational\n",
      "eeg\n",
      "modelling\n",
      "abms\n",
      "nlp\n",
      "magnetohydrodynamics\n",
      "behaviour\n",
      "qcd\n",
      "boltzmann\n",
      "sience\n",
      "qma\n",
      "optimisation\n",
      "biosignals\n",
      "bioimage\n",
      "visualisation\n",
      "eigenvectors\n",
      "pdes\n",
      "modelling\n",
      "rna\n",
      "modelling\n",
      "modelling\n",
      "bioimage\n",
      "hypergeometric\n",
      "eeg\n",
      "qgis\n",
      "optimisation\n",
      "markov\n",
      "snvs\n",
      "blockchain\n",
      "phylodynamics\n",
      "analyse\n",
      "uas\n",
      "tidyverse\n",
      "visualisation\n",
      "tidyverse\n",
      "cmake\n",
      "astroparticle\n",
      "eeg\n",
      "fmri\n",
      "modelling\n",
      "datastructure\n",
      "fmri\n",
      "eeg\n",
      "eeg\n",
      "astrodynamics\n",
      "mcmc\n",
      "archaeology\n",
      "openbim\n",
      "simd\n",
      "gpgpu\n",
      "modelling\n",
      "visualisation\n",
      "pde\n",
      "linguistis\n",
      "dialectology\n",
      "modelling\n",
      "characterisation\n",
      "bibliometrix\n",
      "adverserial\n",
      "modelling\n",
      "multimodel\n",
      "tensorflow\n",
      "optimisation\n",
      "modelling\n",
      "fmri\n",
      "behavioural\n",
      "modelling\n",
      "fmri\n",
      "clinica\n",
      "neurocience\n",
      "nextflow\n",
      "tidyverse\n",
      "rlang\n",
      "mysore\n",
      "funcional\n",
      "sdr\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "networkx\n",
      "astroparticle\n",
      "eeg\n",
      "nmr\n",
      "fhir\n",
      "nlp\n",
      "gggg\n",
      "devops\n",
      "rna\n",
      "vlsi\n",
      "behaviour\n",
      "cosmochemistry\n",
      "practises\n",
      "pdes\n",
      "galerkin\n",
      "wfe\n",
      "nlp\n",
      "fortran\n",
      "ansible\n",
      "archaeology\n",
      "hohai\n",
      "geocomputation\n",
      "uitilities\n",
      "flamegraphs\n",
      "modelling\n",
      "sedimentolgoical\n",
      "ndt\n",
      "metaheuristics\n",
      "mqtt\n",
      "dnssec\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "nlp\n",
      "astrodynamics\n",
      "modelling\n",
      "modelling\n",
      "mecânica\n",
      "termodinâmica\n",
      "uml\n",
      "signalling\n",
      "rnaseq\n",
      "multiomics\n",
      "astroparticle\n",
      "modelling\n",
      "modelling\n",
      "infrostructure\n",
      "parametrization\n",
      "qgis\n",
      "fmri\n",
      "sdr\n",
      "modelling\n",
      "analyses\n",
      "nlp\n",
      "distributionally\n",
      "archaeology\n",
      "kalman\n"
     ]
    }
   ],
   "source": [
    "all_usernames_W2V_Gensim_Idea4, all_domains_W2V_Gensim_Idea4, all_cosine_sims_W2V_Gensim_Idea4 = GetReviewerSample_W2V_Gensim(average_vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "632978d0-ccdb-42b8-8ad9-60764bee3e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32maaronpeikert\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7225\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, - model selection, - structural equation modelling, - multimodel inference, - hierarchical data, , open science, - reproducibility, - dynamic document generation, - containers, - version control\u001b[0m\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7214\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mwjakethompson\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7059\u001b[0m. This reviewers domain interests are \u001b[31mdata management and manipulation, workflow tools, latent variable models (e.g., structural equation models, item response theory, diagnostic classification models, cognitive diagnosis models, etc.), educational assessment and psychometrics\u001b[0m\n",
      "\n",
      "I believe \u001b[32mvc1492a\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7048\u001b[0m. This reviewers domain interests are \u001b[31manomaly detection, natural language processing, graph methods (network analysis)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mfabian-s\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7016\u001b[0m. This reviewers domain interests are \u001b[31mlinear models, additive models, mixed models, bayesian inference, functional data analysis, dimension reduction methods, spatial data analysis\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers_W2V_Gensim(5,all_usernames_W2V_Gensim_Idea4, all_domains_W2V_Gensim_Idea4, all_cosine_sims_W2V_Gensim_Idea4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d28be-91cc-4cdf-b3bf-e8cf74764bc1",
   "metadata": {},
   "source": [
    "# Idea 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a24bb826-c4cb-4b3e-b98e-e099ae0fbb53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vcftoolz\n",
      "vcf\n",
      "vcf\n",
      "vcf\n",
      "vcftoolz\n",
      "vcf\n",
      "snps\n",
      "vcftoolz\n",
      "vcf\n",
      "vcftoolz\n",
      "vcf\n",
      "pypi\n",
      "mcmc\n",
      "visualisation\n",
      "giscience\n",
      "archaeology\n",
      "openmp\n",
      "modelling\n",
      "modelling\n",
      "euroimaging\n",
      "visualisation\n",
      "visualisation\n",
      "frequentist\n",
      "django\n",
      "microservices\n",
      "pde\n",
      "schrodinger\n",
      "knl\n",
      "sowftware\n",
      "characterisation\n",
      "nanophysics\n",
      "viszalization\n",
      "munging\n",
      "biotatistics\n",
      "fmri\n",
      "blockchain\n",
      "postestimation\n",
      "modelling\n",
      "nlp\n",
      "modelling\n",
      "sciencies\n",
      "bibliometry\n",
      "scientometry\n",
      "giscience\n",
      "munging\n",
      "datavis\n",
      "minirg\n",
      "biostats\n",
      "biofinromatics\n",
      "markov\n",
      "modelling\n",
      "biostats\n",
      "nlp\n",
      "modelling\n",
      "pcr\n",
      "chemistryphysical\n",
      "cryptocurrency\n",
      "bdi\n",
      "provers\n",
      "healthit\n",
      "behaviour\n",
      "visualisation\n",
      "astrostatistics\n",
      "analyses\n",
      "nosql\n",
      "modelling\n",
      "visualisation\n",
      "htmlwidgets\n",
      "keras\n",
      "reducation\n",
      "wcet\n",
      "analyses\n",
      "meshless\n",
      "meshfree\n",
      "bioimage\n",
      "visualisation\n",
      "optimisation\n",
      "nlp\n",
      "devsecops\n",
      "visualisation\n",
      "devops\n",
      "nlp\n",
      "sicence\n",
      "mrio\n",
      "lca\n",
      "dsmc\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "visualisation\n",
      "analyses\n",
      "astrodynamics\n",
      "langevin\n",
      "jupyter\n",
      "pde\n",
      "modelling\n",
      "openmp\n",
      "markov\n",
      "archaeology\n",
      "fortran\n",
      "devops\n",
      "pdes\n",
      "pgas\n",
      "macos\n",
      "modelling\n",
      "optimisation\n",
      "algorithmics\n",
      "metabarcoding\n",
      "behavioural\n",
      "astrodynamics\n",
      "ipywidgets\n",
      "visualisation\n",
      "insar\n",
      "mle\n",
      "asdasd\n",
      "sequecning\n",
      "munging\n",
      "gamess\n",
      "delaunay\n",
      "voronoi\n",
      "modelling\n",
      "nlp\n",
      "nlp\n",
      "modelling\n",
      "geocomputation\n",
      "geosimulations\n",
      "astroparticle\n",
      "optimisation\n",
      "modelling\n",
      "scientometrics\n",
      "informetrics\n",
      "pointclouds\n",
      "mapreduce\n",
      "visualisation\n",
      "mcmc\n",
      "visualisation\n",
      "gpus\n",
      "bioinspired\n",
      "nlp\n",
      "kubernetes\n",
      "nlp\n",
      "rstats\n",
      "astroparticle\n",
      "modelling\n",
      "nbody\n",
      "cmb\n",
      "optimisation\n",
      "organisation\n",
      "modelling\n",
      "wikimedia\n",
      "mediawiki\n",
      "astrodynamics\n",
      "modelling\n",
      "fmri\n",
      "modelling\n",
      "magnetohydrodynamics\n",
      "colour\n",
      "modelling\n",
      "fluiddynamics\n",
      "modelling\n",
      "eeg\n",
      "visualisation\n",
      "modelling\n",
      "geomorph\n",
      "visualisation\n",
      "fmri\n",
      "eeg\n",
      "pupillometry\n",
      "nlp\n",
      "netowork\n",
      "goesciences\n",
      "labstraming\n",
      "lca\n",
      "visualisation\n",
      "modelling\n",
      "pdes\n",
      "melnikov\n",
      "pdes\n",
      "characterisation\n",
      "ebsd\n",
      "modelling\n",
      "convolutional\n",
      "visualisation\n",
      "tidyverse\n",
      "aeroelasticity\n",
      "optimisation\n",
      "dfghgtf\n",
      "sotware\n",
      "optimisation\n",
      "geospational\n",
      "phylogeography\n",
      "openfoam\n",
      "modelling\n",
      "nlp\n",
      "dicom\n",
      "fhir\n",
      "devops\n",
      "nlp\n",
      "estatistical\n",
      "visualisation\n",
      "modelling\n",
      "brojournal\n",
      "diffing\n",
      "bindiffing\n",
      "isomorphism\n",
      "behaviour\n",
      "rnaseq\n",
      "munging\n",
      "mklr\n",
      "modelling\n",
      "abm\n",
      "modelling\n",
      "mcmc\n",
      "mcmc\n",
      "newtonian\n",
      "nilm\n",
      "deeplearning\n",
      "segmantation\n",
      "pdes\n",
      "eeg\n",
      "ieeg\n",
      "nlp\n",
      "dataviz\n",
      "snv\n",
      "humour\n",
      "multigrid\n",
      "satisfiability\n",
      "visualisation\n",
      "archaeology\n",
      "archaeology\n",
      "visualisation\n",
      "munging\n",
      "blockchain\n",
      "modelling\n",
      "modelling\n",
      "humanties\n",
      "pupillometry\n",
      "fmm\n",
      "visualisation\n",
      "visualisation\n",
      "mcmc\n",
      "nlp\n",
      "markov\n",
      "pyrometallurgy\n",
      "thermochemistry\n",
      "visualisation\n",
      "cdisc\n",
      "modelling\n",
      "informetrics\n",
      "modelling\n",
      "milps\n",
      "mmilps\n",
      "gwas\n",
      "jupyter\n",
      "modelling\n",
      "modelling\n",
      "behavioural\n",
      "organisational\n",
      "eeg\n",
      "modelling\n",
      "abms\n",
      "nlp\n",
      "magnetohydrodynamics\n",
      "behaviour\n",
      "qcd\n",
      "boltzmann\n",
      "sience\n",
      "qma\n",
      "optimisation\n",
      "biosignals\n",
      "bioimage\n",
      "visualisation\n",
      "eigenvectors\n",
      "pdes\n",
      "modelling\n",
      "rna\n",
      "modelling\n",
      "modelling\n",
      "bioimage\n",
      "hypergeometric\n",
      "eeg\n",
      "qgis\n",
      "optimisation\n",
      "markov\n",
      "snvs\n",
      "blockchain\n",
      "phylodynamics\n",
      "analyse\n",
      "uas\n",
      "tidyverse\n",
      "visualisation\n",
      "tidyverse\n",
      "cmake\n",
      "astroparticle\n",
      "eeg\n",
      "fmri\n",
      "modelling\n",
      "datastructure\n",
      "fmri\n",
      "eeg\n",
      "eeg\n",
      "astrodynamics\n",
      "mcmc\n",
      "archaeology\n",
      "openbim\n",
      "simd\n",
      "gpgpu\n",
      "modelling\n",
      "visualisation\n",
      "pde\n",
      "linguistis\n",
      "dialectology\n",
      "modelling\n",
      "characterisation\n",
      "bibliometrix\n",
      "adverserial\n",
      "modelling\n",
      "multimodel\n",
      "tensorflow\n",
      "optimisation\n",
      "modelling\n",
      "fmri\n",
      "behavioural\n",
      "modelling\n",
      "fmri\n",
      "clinica\n",
      "neurocience\n",
      "nextflow\n",
      "tidyverse\n",
      "rlang\n",
      "mysore\n",
      "funcional\n",
      "sdr\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "networkx\n",
      "astroparticle\n",
      "eeg\n",
      "nmr\n",
      "fhir\n",
      "nlp\n",
      "gggg\n",
      "devops\n",
      "rna\n",
      "vlsi\n",
      "behaviour\n",
      "cosmochemistry\n",
      "practises\n",
      "pdes\n",
      "galerkin\n",
      "wfe\n",
      "nlp\n",
      "fortran\n",
      "ansible\n",
      "archaeology\n",
      "hohai\n",
      "geocomputation\n",
      "uitilities\n",
      "flamegraphs\n",
      "modelling\n",
      "sedimentolgoical\n",
      "ndt\n",
      "metaheuristics\n",
      "mqtt\n",
      "dnssec\n",
      "modelling\n",
      "visualisation\n",
      "modelling\n",
      "modelling\n",
      "nlp\n",
      "astrodynamics\n",
      "modelling\n",
      "modelling\n",
      "mecânica\n",
      "termodinâmica\n",
      "uml\n",
      "signalling\n",
      "rnaseq\n",
      "multiomics\n",
      "astroparticle\n",
      "modelling\n",
      "modelling\n",
      "infrostructure\n",
      "parametrization\n",
      "qgis\n",
      "fmri\n",
      "sdr\n",
      "modelling\n",
      "analyses\n",
      "nlp\n",
      "distributionally\n",
      "archaeology\n",
      "kalman\n"
     ]
    }
   ],
   "source": [
    "texts, arr = MakeGreenRedText(Paper_interest,False)\n",
    "average_vector_text = MakingPaperVector_Idea6_Gensim(arr, model, printer=True)\n",
    "\n",
    "all_usernames_W2V_Gensim_Idea_6, all_domains_W2V_Gensim_Idea_6, all_cosine_sims_W2V_Gensim_Idea_6 = GetReviewerSample_W2V_Gensim(average_vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6c4a79e-da47-4ca0-9ca3-256008eed688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32maaronpeikert\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7225\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, - model selection, - structural equation modelling, - multimodel inference, - hierarchical data, , open science, - reproducibility, - dynamic document generation, - containers, - version control\u001b[0m\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7214\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mwjakethompson\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7059\u001b[0m. This reviewers domain interests are \u001b[31mdata management and manipulation, workflow tools, latent variable models (e.g., structural equation models, item response theory, diagnostic classification models, cognitive diagnosis models, etc.), educational assessment and psychometrics\u001b[0m\n",
      "\n",
      "I believe \u001b[32mvc1492a\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7048\u001b[0m. This reviewers domain interests are \u001b[31manomaly detection, natural language processing, graph methods (network analysis)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mfabian-s\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7016\u001b[0m. This reviewers domain interests are \u001b[31mlinear models, additive models, mixed models, bayesian inference, functional data analysis, dimension reduction methods, spatial data analysis\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers_W2V_Gensim(5,all_usernames_W2V_Gensim_Idea_6, all_domains_W2V_Gensim_Idea_6, all_cosine_sims_W2V_Gensim_Idea_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500f122-41d9-4ec6-8156-a279e8454d5c",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d1b96c2-31c0-4e30-8e96-2e4b2dba008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972af138-ac82-4b90-a794-5c17869c656a",
   "metadata": {},
   "source": [
    "# Idea 3 TF (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07cfdf15-3f8c-47f6-b641-8a47dbbd930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tf = Get_Top_Words_tf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34e0caba-c2f5-48a2-ad98-1b24f99360b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['variant', 'vcf', 'file', 'package', 'comparing', 'call', 'format',\n",
       "       'et', 'vcftoolz', 'calling', 'compare', 'algorithm', 'software',\n",
       "       'capability', 'python', 'evaluating', 'multiple', 'november',\n",
       "       'work', 'food'], dtype='<U21')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2659297c-c2d0-4ca7-9f4f-1ea4ba3da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_vectors = GetReviewer_Vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fc3bd34f-618c-456d-8f6b-eddbf2da41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_top20= ''\n",
    "for i in top20_tf:\n",
    "    doc_top20 = doc_top20 + i +' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5cf9b26c-109d-4684-abbe-88bf967b0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usernames_spacy_Idea_3_TF, all_domains_spacy_Idea_3_TF, all_cosine_sims_spacy_Idea_3_TF = GetCosineSims(model(doc_top20).vector, reviewer_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "608ef328-2f6c-4f07-aa8b-a16ae36c1e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8388\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mjarrah42\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8261\u001b[0m. This reviewers domain interests are \u001b[31mhigh performance/scientific computing, operating systems, distributed systems, parallel programming, software engineering, user interfaces, debugging, performance analysis, development tools, security, web development, internet of things\u001b[0m\n",
      "\n",
      "I believe \u001b[32mscivision\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8231\u001b[0m. This reviewers domain interests are \u001b[31mbuild systems, file i/o, benchmarking, multi-code language interfaces\u001b[0m\n",
      "\n",
      "I believe \u001b[32malexpghayes\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8210\u001b[0m. This reviewers domain interests are \u001b[31mi'm interested in making sure that r packages for modelling have useful and intuitive interfaces and documentation. i'm not interested in double checking theory and correctness, but making sure that a new user can quickly and easily get the results they want.\u001b[0m\n",
      "\n",
      "I believe \u001b[32mzeroset\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8166\u001b[0m. This reviewers domain interests are \u001b[31mscientific computing, simulation software, high performance computing, parallel computing, template meta programming, multi agent simulation, research software\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers(5, all_usernames_spacy_Idea_3_TF, all_domains_spacy_Idea_3_TF, all_cosine_sims_spacy_Idea_3_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17a634f-7c14-4812-8ad1-af5659043fc2",
   "metadata": {},
   "source": [
    "# Idea 3 TF-IDF (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "318522ac-a001-40a3-8379-9ef63165b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_tf_idf = Get_Top_Words_tf_idf(Paper_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "14e1cd08-0799-4615-a2dd-eacd859cccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vcf', 'rtg', 'venn', 'benchmarking', 'concordance', 'spreadsheet',\n",
       "       'python', 'snp', 'evaluating', 'algorithm', 'variant', 'caller',\n",
       "       'comparing', 'compare', 'sequencing', 'file', 'artifact',\n",
       "       'package', 'capability', 'facilitates'], dtype='<U13')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d9a53d9-cfe4-4b56-ac65-621d37507cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_top20= ''\n",
    "for i in top20_tf_idf:\n",
    "    doc_top20 = doc_top20 + i +' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "798932bc-ef1a-4c2a-baa8-a69e4e0437c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usernames_spacy_Idea_3_TF_IDF, all_domains_spacy_Idea_3_TF_IDF, all_cosine_sims_spacy_Idea_3_TF_IDF = GetCosineSims(model(doc_top20).vector, reviewer_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df0ad432-e4ba-4204-b9ab-4096b94b956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7946\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mzbeekman\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7623\u001b[0m. This reviewers domain interests are \u001b[31mcomputational fluid dynamics (cfd), fortran tools, utilities, libraries, solvers, programs, ci/cd & devops for computational science and engineering, hpc applications, frameworks, & tools, numerical solution of pdes, performance analysis & performance engineering tools, multi-physics frameworks & applications, legacy application refactoring tools, parallel & pgas runtimes/rtls, package managers, macos tools & utilities\u001b[0m\n",
      "\n",
      "I believe \u001b[32mcamillescott\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7499\u001b[0m. This reviewers domain interests are \u001b[31mbioinformatics, computational biology, graph theory, network analysis, data visualization, testing, workflow tools\u001b[0m\n",
      "\n",
      "I believe \u001b[32mGregoryAshton\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7475\u001b[0m. This reviewers domain interests are \u001b[31mopen source software, statistics, bayesian inference/stochastic sampling, data visualization\u001b[0m\n",
      "\n",
      "I believe \u001b[32mnjtierney\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7463\u001b[0m. This reviewers domain interests are \u001b[31mdata visualisation, tools that facilitate data analysis, exploratory data analysis, statistics\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers(5, all_usernames_spacy_Idea_3_TF_IDF, all_domains_spacy_Idea_3_TF_IDF, all_cosine_sims_spacy_Idea_3_TF_IDF )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f0a94-318e-4bfe-ba5c-f5f46468f7db",
   "metadata": {},
   "source": [
    "# Idea 4 (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dff4455c-addb-4081-bb22-2ed29487c065",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Only Green Text - No Other Preprocessing ###\n",
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32malexpghayes\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8612\u001b[0m. This reviewers domain interests are \u001b[31mi'm interested in making sure that r packages for modelling have useful and intuitive interfaces and documentation. i'm not interested in double checking theory and correctness, but making sure that a new user can quickly and easily get the results they want.\u001b[0m\n",
      "\n",
      "I believe \u001b[32mmichaelberks\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8527\u001b[0m. This reviewers domain interests are \u001b[31mmedical imaging, image processing, compute vision, machine learning/ai applied to images, general scientific/numerical data processing (unless requiring specialist domain specific knowledge outside of the areas listed above)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mlucask07\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8159\u001b[0m. This reviewers domain interests are \u001b[31minstrument control, (possibly) image analysis, experiment data analysis (physics or ee based)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mr3w0p\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8157\u001b[0m. This reviewers domain interests are \u001b[31minternet of things, complex event processing, fault tolerance, machine learning\u001b[0m\n",
      "\n",
      "I believe \u001b[32mDarthpathos\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8149\u001b[0m. This reviewers domain interests are \u001b[31mhealthcare, time series, data quality (including missing data), survey analysis, repeated events, longitudinal data\u001b[0m\n",
      "\n",
      "\n",
      "### Green Text & Lemmasation ###\n",
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32maaronpeikert\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8512\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, - model selection, - structural equation modelling, - multimodel inference, - hierarchical data, , open science, - reproducibility, - dynamic document generation, - containers, - version control\u001b[0m\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8461\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mmichaelberks\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8455\u001b[0m. This reviewers domain interests are \u001b[31mmedical imaging, image processing, compute vision, machine learning/ai applied to images, general scientific/numerical data processing (unless requiring specialist domain specific knowledge outside of the areas listed above)\u001b[0m\n",
      "\n",
      "I believe \u001b[32malexpghayes\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8413\u001b[0m. This reviewers domain interests are \u001b[31mi'm interested in making sure that r packages for modelling have useful and intuitive interfaces and documentation. i'm not interested in double checking theory and correctness, but making sure that a new user can quickly and easily get the results they want.\u001b[0m\n",
      "\n",
      "I believe \u001b[32mjarrah42\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8378\u001b[0m. This reviewers domain interests are \u001b[31mhigh performance/scientific computing, operating systems, distributed systems, parallel programming, software engineering, user interfaces, debugging, performance analysis, development tools, security, web development, internet of things\u001b[0m\n",
      "\n",
      "\n",
      "### Green Text & Lemmasation & Unique Words ###\n",
      "Hello.\n",
      " I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32mmichaelberks\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8991\u001b[0m. This reviewers domain interests are \u001b[31mmedical imaging, image processing, compute vision, machine learning/ai applied to images, general scientific/numerical data processing (unless requiring specialist domain specific knowledge outside of the areas listed above)\u001b[0m\n",
      "\n",
      "I believe \u001b[32maaronpeikert\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8800\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, - model selection, - structural equation modelling, - multimodel inference, - hierarchical data, , open science, - reproducibility, - dynamic document generation, - containers, - version control\u001b[0m\n",
      "\n",
      "I believe \u001b[32mfelixhenninger\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8741\u001b[0m. This reviewers domain interests are \u001b[31mcognitive/behavioral science, online/browser-based data collection, open data/open science, process-level data analyses and preprocessing/data wrangling (eye-tracking, movement tracking, not a neuroimaging expert though)\u001b[0m\n",
      "\n",
      "I believe \u001b[32malexpghayes\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8718\u001b[0m. This reviewers domain interests are \u001b[31mi'm interested in making sure that r packages for modelling have useful and intuitive interfaces and documentation. i'm not interested in double checking theory and correctness, but making sure that a new user can quickly and easily get the results they want.\u001b[0m\n",
      "\n",
      "I believe \u001b[32mGalenStocking\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.8706\u001b[0m. This reviewers domain interests are \u001b[31mstatistics, machine learning, data science, including cleaning, validation, etc., network analysis\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts, arr = MakeGreenRedText(Paper_interest, False)\n",
    "W2V_spaCy_Processing(texts, green_text=True, lemma=True, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c7232-0f8e-4ab8-bb56-10cdeff87b9e",
   "metadata": {},
   "source": [
    "# Idea 6 spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7cd95136-f4e6-432e-89c3-b94eee795061",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_vectors = GetReviewer_Vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae6fd130-0529-4fcd-86f7-2ab2d91b5b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32mmichaelberks\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7870\u001b[0m. This reviewers domain interests are \u001b[31mmedical imaging, image processing, compute vision, machine learning/ai applied to images, general scientific/numerical data processing (unless requiring specialist domain specific knowledge outside of the areas listed above)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mSarthakJariwala\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7668\u001b[0m. This reviewers domain interests are \u001b[31mvisualization, image analysis, materials science, api development, climate, solar technology, general data acquisition & analysis\u001b[0m\n",
      "\n",
      "I believe \u001b[32mbrunaw\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7661\u001b[0m. This reviewers domain interests are \u001b[31mstatistics, machine learning, open research, music information retrieval\u001b[0m\n",
      "\n",
      "I believe \u001b[32mcrew102\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7643\u001b[0m. This reviewers domain interests are \u001b[31mgeneral software development and data science tools/topics\u001b[0m\n",
      "\n",
      "I believe \u001b[32mGalenStocking\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7612\u001b[0m. This reviewers domain interests are \u001b[31mstatistics, machine learning, data science, including cleaning, validation, etc., network analysis\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_vector_text = Get_Paper_Vector_Idea6_SpaCy(arr,model)\n",
    "all_usernames_spacy_Idea_6_A, all_domains_spacy_Idea_6_A, all_cosine_sims_spacy_Idea_6_A = GetCosineSims(average_vector_text, reviewer_vectors)\n",
    "  \n",
    "TopReviewers(5, all_usernames_spacy_Idea_6_A, all_domains_spacy_Idea_6_A, all_cosine_sims_spacy_Idea_6_A )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd10de16-b4b3-4bb9-927c-4841d05eae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32madammichaelwood\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7932\u001b[0m. This reviewers domain interests are \u001b[31mdocumentation, community, project management, continuous deployment, databases, web standards, accessibility, diversity, education, non profit, music, nlp, humanities, latex, sphinx (documentation engine), markdown, markup languages\u001b[0m\n",
      "\n",
      "I believe \u001b[32mharishpillay\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7849\u001b[0m. This reviewers domain interests are \u001b[31methics in code, secure coding, open source licensing\u001b[0m\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7598\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mjarrah42\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7578\u001b[0m. This reviewers domain interests are \u001b[31mhigh performance/scientific computing, operating systems, distributed systems, parallel programming, software engineering, user interfaces, debugging, performance analysis, development tools, security, web development, internet of things\u001b[0m\n",
      "\n",
      "I believe \u001b[32merik-whiting\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7520\u001b[0m. This reviewers domain interests are \u001b[31msoftware testing, software architecture, information systems, databases\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_list_lemma = Idea6_lemma_Text(arr)\n",
    "average_vector_text2 = Get_Paper_Vector_Idea6_SpaCy(text_list_lemma,model)\n",
    "all_usernames_spacy_Idea_6_B, all_domains_spacy_Idea_6_B, all_cosine_sims_spacy_Idea_6_B  = GetCosineSims(average_vector_text2, reviewer_vectors)\n",
    "TopReviewers(5, all_usernames_spacy_Idea_6_B, all_domains_spacy_Idea_6_B, all_cosine_sims_spacy_Idea_6_B ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "148fdfef-4897-4c39-b035-0a714e8a3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32madammichaelwood\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7958\u001b[0m. This reviewers domain interests are \u001b[31mdocumentation, community, project management, continuous deployment, databases, web standards, accessibility, diversity, education, non profit, music, nlp, humanities, latex, sphinx (documentation engine), markdown, markup languages\u001b[0m\n",
      "\n",
      "I believe \u001b[32mharishpillay\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7867\u001b[0m. This reviewers domain interests are \u001b[31methics in code, secure coding, open source licensing\u001b[0m\n",
      "\n",
      "I believe \u001b[32msonal-raj\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7624\u001b[0m. This reviewers domain interests are \u001b[31mpython, distributed computing, real time processing, image processing, graphs & graph databases, nosql databases, algorithms, software development methodologies\u001b[0m\n",
      "\n",
      "I believe \u001b[32mjarrah42\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7611\u001b[0m. This reviewers domain interests are \u001b[31mhigh performance/scientific computing, operating systems, distributed systems, parallel programming, software engineering, user interfaces, debugging, performance analysis, development tools, security, web development, internet of things\u001b[0m\n",
      "\n",
      "I believe \u001b[32merik-whiting\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.7543\u001b[0m. This reviewers domain interests are \u001b[31msoftware testing, software architecture, information systems, databases\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_list_unique_lemma = Idea6_unique_lemma_Text(arr)\n",
    "average_vector_text3 = Get_Paper_Vector_Idea6_SpaCy(text_list_unique_lemma,model)\n",
    "all_usernames_spacy_Idea_6_C, all_domains_spacy_Idea_6_C, all_cosine_sims_spacy_Idea_6_C = GetCosineSims(average_vector_text3, reviewer_vectors)\n",
    "TopReviewers(5, all_usernames_spacy_Idea_6_C, all_domains_spacy_Idea_6_C, all_cosine_sims_spacy_Idea_6_C ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c655080-9d25-42c1-a4f5-e068e362ad9e",
   "metadata": {},
   "source": [
    "# Idea 9 (Sense2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd8a050e-f0a7-4364-8d12-6c28dba86a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sense2vec import Sense2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f4d441c-c475-488a-ad58-eb480f53a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2v = Sense2Vec().from_disk(\"../s2v_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "887c8790-62a0-4269-bcd6-72e0aa8a6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "62e7997c-c7d6-4d3f-8697-20ce5713f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, arr = MakeGreenRedText(Paper_interest,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f25c36dd-7952-4910-a69e-cc9eb1a1907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_word_vec = GetPaperVector_Sense2Vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d9769905-9376-449f-b0d4-dfeb57af91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usernames_sense2vec, all_domains_sense2vec, all_cosine_sims_sense2vec = GetReviewerSample_Sense2Vec(average_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "da49a740-7fa7-42a7-9d6d-98ba52d9d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "I have found 5 possible reviewers for this paper.\n",
      "\n",
      "I believe \u001b[32mgithub.com/leonardojaneis\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.9185\u001b[0m. This reviewers domain interests are \u001b[31mparallel programming, distributed systems, complex data, pattern recognition, biometrics and database\u001b[0m\n",
      "\n",
      "I believe \u001b[32maaronpeikert\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.9149\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, - model selection, - structural equation modelling, - multimodel inference, - hierarchical data, , open science, - reproducibility, - dynamic document generation, - containers, - version control\u001b[0m\n",
      "\n",
      "I believe \u001b[32mvc1492a\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.9116\u001b[0m. This reviewers domain interests are \u001b[31manomaly detection, natural language processing, graph methods (network analysis)\u001b[0m\n",
      "\n",
      "I believe \u001b[32mwjakethompson\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.9097\u001b[0m. This reviewers domain interests are \u001b[31mdata management and manipulation, workflow tools, latent variable models (e.g., structural equation models, item response theory, diagnostic classification models, cognitive diagnosis models, etc.), educational assessment and psychometrics\u001b[0m\n",
      "\n",
      "I believe \u001b[32mroad2stat\u001b[0m will be a good reviewer for this paper. Their domain interests and this paper have a cosine similairity score of \u001b[34m0.9079\u001b[0m. This reviewers domain interests are \u001b[31mmachine learning, bioinformatics, cheminformatics, drug discovery, variable selection, high-dimensional data, biological sequence analysis\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TopReviewers(5, all_usernames_sense2vec, all_domains_sense2vec, all_cosine_sims_sense2vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445089dc-75dc-4996-a43b-ab75c52b9738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
